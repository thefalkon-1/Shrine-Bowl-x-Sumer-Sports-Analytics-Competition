{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline: OL-DL 1v1 Rep Detection\n",
    "\n",
    "**Consolidated pipeline for processing practice tracking data with coordinate normalization.**\n",
    "\n",
    "## Workflow\n",
    "1. **Load Data** - Load parquet file\n",
    "2. **Inspect Drill Types** - See counts per drill type\n",
    "3. **Filter Drill Type** - Select one drill type to analyze\n",
    "4. **Generate Frame IDs** - Create canonical frame numbering\n",
    "5. **Visualize Raw Data** - Find LOS position and determine orientation (raw coords 0-120)\n",
    "6. **Apply Transformation** - Normalize coordinates based on LOS and orientation\n",
    "7. **Filter to Rep Period** - Narrow to the rep period, mark OL/DL\n",
    "8. **Run Algorithm** - Detect individual reps\n",
    "9. **Visualize Reps** - Review each detected rep (normalized coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports complete.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "from matplotlib.patches import Rectangle\n",
    "from pathlib import Path\n",
    "from math import inf\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import IntSlider, Play, Dropdown, Button, HBox, VBox, Output, jslink\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib widget\n",
    "\n",
    "print(\"Imports complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using player ID column: zebra_id\n",
      "shape: (9, 2)\n",
      "┌────────────────────────────┬─────────┐\n",
      "│ drill_type                 ┆ count   │\n",
      "│ ---                        ┆ ---     │\n",
      "│ str                        ┆ u32     │\n",
      "╞════════════════════════════╪═════════╡\n",
      "│ Bigs 1 on 1 - Skill 7 on 7 ┆ 3567162 │\n",
      "│ Bigs 9 on 7 - Skill 1 on 1 ┆ 3567162 │\n",
      "│ Team                       ┆ 3567162 │\n",
      "│ Best of 1 on 1             ┆ 3567162 │\n",
      "│ Indy                       ┆ 3567162 │\n",
      "│ Pre Practice               ┆ 3567162 │\n",
      "│ SPT 2                      ┆ 3567162 │\n",
      "│ SPT                        ┆ 3567162 │\n",
      "│ Stretch                    ┆ 3567162 │\n",
      "└────────────────────────────┴─────────┘\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: MANUAL CONFIGURATION (Skip to Cell 3 to use created dict; I followed this process to create the dict)\n",
    "# Path to the practice parquet file\n",
    "# Replace with your own path to practice files \n",
    "PRACTICE_FILE = Path(\"~/Desktop/ShrineBowlSumerSportsAnalyticsCompetition/practice_data/2024_West_Practice_1.snappy.parquet\")\n",
    "\n",
    "ID_COL_CANDIDATES = [\"zebra_id\", \"tid\", \"id\"]  # Possible player ID column names\n",
    "TRACKING_METRICS = [\"a\", \"dir\", \"sa\", \"dis\", \"s\", \"x\", \"y\", \"z\"]  # Motion metrics\n",
    "\n",
    "# Scan the parquet file (lazy evaluation)\n",
    "tracking_scan = pl.scan_parquet(PRACTICE_FILE)\n",
    "\n",
    "# Detect schema and find player ID column\n",
    "try:\n",
    "    cols = tracking_scan.collect_schema().names()\n",
    "except Exception:\n",
    "    cols = list(tracking_scan.schema.keys())\n",
    "\n",
    "player_id_col = next((c for c in ID_COL_CANDIDATES if c in cols), None)\n",
    "if player_id_col is None:\n",
    "    raise ValueError(f\"Could not find player ID column. Tried: {ID_COL_CANDIDATES}\")\n",
    "\n",
    "print(f\"Using player ID column: {player_id_col}\")\n",
    "\n",
    "# Select columns that exist in the dataset\n",
    "keep_cols_wanted = [\n",
    "    \"dataset_id\", \"dataset_name\", \"dataset_intensity\", \"dataset_game_id\", \"session_id\",\n",
    "    \"drill_type\", \"entity_type\", player_id_col, \"gsis_id\", \"jersey_number\", \"ts\",\n",
    "] + TRACKING_METRICS\n",
    "keep_cols = [c for c in keep_cols_wanted if c in cols]\n",
    "\n",
    "# Load data (filter to players only)\n",
    "df_raw = (\n",
    "    tracking_scan\n",
    "    .select(keep_cols)\n",
    "    .filter(pl.col(\"entity_type\") == \"player\") # Note: Football is sometimes not present in OL-DL drill sessions\n",
    "    .with_columns([\n",
    "        pl.col(\"ts\").cast(pl.Utf8),\n",
    "        pl.col(player_id_col).cast(pl.Utf8).alias(\"id\"),\n",
    "    ])\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "# Count the drill types; pick one for 1 on 1\n",
    "drill_counts = df_raw.group_by(\"drill_type\").agg(pl.len().alias(\"count\")).sort(\"count\", descending=True)\n",
    "with pl.Config(tbl_rows=-1):\n",
    "    print(drill_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CELL 2: FILTER TO DRILL TYPE, GENERATE CANONICAL FRAME ID'S BASED ON TIMESTAMP\n",
    "From above, select the drill type you want to analyze. Then, filter to the drill type and create frame ID's based on the unique timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DRILL_TYPE_FILTER = \"Bigs 1 on 1 - Skill 7 on 7\"  # Change to match the specific drill type\n",
    "\n",
    "# Filter to the selected drill type\n",
    "df_filtered = df_raw.filter(pl.col(\"drill_type\") == DRILL_TYPE_FILTER)\n",
    "\n",
    "# Build frame_map from unique timestamps (sorted)\n",
    "frame_map = (\n",
    "    df_filtered\n",
    "    .select(\"ts\")\n",
    "    .unique()\n",
    "    .sort(\"ts\")\n",
    "    .with_row_index(name=\"frame_id\", offset=0)\n",
    ")\n",
    "\n",
    "# Join frame_id back to filtered data\n",
    "df_with_frames = df_filtered.join(frame_map, on=\"ts\", how=\"left\")\n",
    "\n",
    "# Add parsed timestamp\n",
    "df_full_raw = df_with_frames.with_columns(pl.col(\"ts\").str.to_datetime().alias(\"parsed_ts\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CELL 3: CREATE VISUALIZATION\n",
    "We will create a visualization of the data in order to obtain needed configuration parameters to run the pipeline. We need the following parameters:\n",
    "\n",
    "1. START_TS: The timestamp of the beginning of the drill period ()\n",
    "2. END_TS: The timestamp of the end of the drill period\n",
    "3. LOS: The line of scrimmage for the 1-on-1 drill (can be inferred from where oline is lined up)\n",
    "4. olinemen: List of oline player jersey numbers\n",
    "5. dlinemen: List of dline player jersey numbers\n",
    "6. Flip: Boolean indicating whether the drill is flipped (oline is assumed to be to the right of the LOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visualization ready: 71388 frames (full field, ORIGINAL coordinates)\n",
      "Time range: 2024-01-27T15:51:08.700 to 2024-01-27T17:50:11.400\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a035dea822497981e65d8300dbfba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Play(value=0, max=71387), Button(description='<', style=ButtonStyle()), Button(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Viz (Plotly)\n",
    "# Full field, raw coordinates with jersey numbers over markers\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Get unique frames for slider (from raw data)\n",
    "frames_view = df_full_raw.select([\"frame_id\", \"ts\", \"parsed_ts\"]).unique().sort(\"frame_id\")\n",
    "frame_ids = frames_view[\"frame_id\"].to_list()\n",
    "timestamps = frames_view[\"ts\"].to_list()\n",
    "n_frames = len(frame_ids)\n",
    "\n",
    "print(f\"Visualization ready: {n_frames} frames (full field, ORIGINAL coordinates)\")\n",
    "print(f\"Time range: {timestamps[0]} to {timestamps[-1]}\")\n",
    "\n",
    "X_MIN = 0.0\n",
    "X_MAX = 125.0\n",
    "Y_MIN = 0.0\n",
    "Y_MAX = 53.3\n",
    "\n",
    "fig = go.FigureWidget()\n",
    "\n",
    "# Yard lines (every 5 yards, bold every 10)\n",
    "for yard in range(0, 121, 5):\n",
    "    width = 2 if yard % 10 == 0 else 1\n",
    "    fig.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=yard, x1=yard,\n",
    "        y0=Y_MIN, y1=Y_MAX,\n",
    "        line=dict(color=\"white\", width=width),\n",
    "        layer=\"below\",\n",
    "    )\n",
    "\n",
    "# Goal lines\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=10, x1=10,\n",
    "    y0=Y_MIN, y1=Y_MAX,\n",
    "    line=dict(color=\"white\", width=3),\n",
    "    layer=\"below\",\n",
    ")\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=110, x1=110,\n",
    "    y0=Y_MIN, y1=Y_MAX,\n",
    "    line=dict(color=\"white\", width=3),\n",
    "    layer=\"below\",\n",
    ")\n",
    "\n",
    "# Yard numbers\n",
    "annotations = []\n",
    "for yard in range(20, 110, 10):\n",
    "    num = yard - 10 if yard <= 60 else 110 - yard\n",
    "    annotations.append(dict(x=yard, y=5, text=str(num), showarrow=False, font=dict(color=\"white\", size=10)))\n",
    "    annotations.append(dict(x=yard, y=48, text=str(num), showarrow=False, font=dict(color=\"white\", size=10)))\n",
    "\n",
    "# Players (markers + jersey numbers)\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[], y=[], mode=\"markers+text\", name=\"Players\",\n",
    "    marker=dict(size=12, color=\"steelblue\", line=dict(color=\"white\", width=1.5)),\n",
    "    text=[], textposition=\"middle center\",\n",
    "    textfont=dict(color=\"white\", size=9),\n",
    "    showlegend=True,\n",
    "))\n",
    "\n",
    "# Ball\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[], y=[], mode=\"markers\", name=\"Ball\",\n",
    "    marker=dict(size=9, color=\"saddlebrown\", line=dict(color=\"white\", width=1.2)),\n",
    "    showlegend=True,\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=900, height=450,\n",
    "    title=\"\",\n",
    "    showlegend=True,\n",
    "    legend=dict(x=0.02, y=0.98),\n",
    "    plot_bgcolor=\"#2e7d32\",\n",
    "    paper_bgcolor=\"white\",\n",
    "    annotations=annotations,\n",
    ")\n",
    "\n",
    "fig.update_xaxes(range=[X_MIN, X_MAX], title=\"X (yards)\", showgrid=False, zeroline=False)\n",
    "fig.update_yaxes(range=[Y_MIN, Y_MAX], title=\"Y (yards)\", showgrid=False, zeroline=False, scaleanchor=\"x\", scaleratio=1)\n",
    "\n",
    "# ====== Widgets ======\n",
    "play = Play(value=0, min=0, max=max(0, n_frames - 1), step=1, interval=100)\n",
    "slider = IntSlider(min=0, max=max(0, n_frames - 1), step=1, value=0, description=\"Frame\")\n",
    "back_button = Button(description=\"<\")\n",
    "forward_button = Button(description=\">\")\n",
    "\n",
    "\n",
    "def update_frame(frame_idx):\n",
    "    idx = max(0, min(int(frame_idx), n_frames - 1))\n",
    "    fid = frame_ids[idx]\n",
    "    ts = timestamps[idx]\n",
    "\n",
    "    frame_data = df_full_raw.filter(pl.col(\"frame_id\") == fid)\n",
    "    if frame_data.height == 0:\n",
    "        fig.data[0].x = []\n",
    "        fig.data[0].y = []\n",
    "        fig.data[0].text = []\n",
    "        fig.data[1].x = []\n",
    "        fig.data[1].y = []\n",
    "        fig.layout.title = f\"EXPLORATION (Raw Coords) | Frame {fid} / {frame_ids[-1]} | {ts} | Players: 0\"\n",
    "        return\n",
    "\n",
    "    ball_data = frame_data.filter(pl.col(\"entity_type\") == \"ball\")\n",
    "    player_points = frame_data.filter(pl.col(\"entity_type\") != \"ball\")\n",
    "\n",
    "    x = player_points[\"x\"].to_list()\n",
    "    y = player_points[\"y\"].to_list()\n",
    "    jerseys = [str(j) for j in player_points[\"jersey_number\"].to_list()]\n",
    "\n",
    "    fig.data[0].x = x\n",
    "    fig.data[0].y = y\n",
    "    fig.data[0].text = jerseys\n",
    "\n",
    "    fig.data[1].x = ball_data[\"x\"].to_list()\n",
    "    fig.data[1].y = ball_data[\"y\"].to_list()\n",
    "\n",
    "    fig.layout.title = f\"EXPLORATION (Raw Coords) | Frame {fid} / {frame_ids[-1]} | {ts} | Players: {len(jerseys)}\"\n",
    "\n",
    "\n",
    "def on_frame_change(change):\n",
    "    if change[\"name\"] == \"value\":\n",
    "        update_frame(change[\"new\"])\n",
    "\n",
    "\n",
    "def step_frame(delta):\n",
    "    slider.value = max(0, min(slider.value + delta, n_frames - 1))\n",
    "\n",
    "jslink((play, \"value\"), (slider, \"value\"))\n",
    "slider.observe(on_frame_change, names=\"value\")\n",
    "back_button.on_click(lambda _: step_frame(-1))\n",
    "forward_button.on_click(lambda _: step_frame(1))\n",
    "\n",
    "controls = HBox([play, back_button, forward_button, slider])\n",
    "ui = VBox([controls, fig])\n",
    "display(ui)\n",
    "\n",
    "update_frame(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CELL 4: APPLY COORDINATE TRANSFORMATIONS\n",
    "To make the coordinate system across each session, we need to use LOS and Flip to transform the cordinate system so that 1) the LOS is always at x = 0 and 2) the oline is always to the right of the LOS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set these after using the exploration visualization to inspect raw data\n",
    "LOS = 105.0              # Line of scrimmage x-coordinate in ORIGINAL data\n",
    "FLIP_ORIENTATION = False # Set TRUE if DL is to the right of LOS in original data\n",
    "\n",
    "def transform_coordinates(df: pl.DataFrame, los: float, flip_orientation: bool) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Transform coordinates based on LOS and orientation configuration.\n",
    "\n",
    "    After transformation:\n",
    "    - LOS is at x = 0\n",
    "    - DL should be at x < 0 (left of LOS)\n",
    "    - OL should be at x > 0 (right of LOS)\n",
    "    - DL moves in +x direction when rep starts\n",
    "\n",
    "    Parameters:\n",
    "        df: DataFrame with x, y, dir columns\n",
    "        los: Line of scrimmage x-coordinate in original data\n",
    "        flip_orientation: If True, flip x and y around field center before normalizing\n",
    "    \"\"\"\n",
    "    if flip_orientation:\n",
    "        # Flip around field center (60, 26.65), then normalize LOS to 0\n",
    "        # Combined formula: x_new = los - x, y_new = 53.3 - y\n",
    "        # Also flip direction angle by 180 degrees\n",
    "        df = df.with_columns([\n",
    "            (pl.lit(los) - pl.col(\"x\")).alias(\"x\"),\n",
    "            (pl.lit(53.3) - pl.col(\"y\")).alias(\"y\"),\n",
    "            ((pl.col(\"dir\") + 180) % 360).alias(\"dir\"),  # Rotate direction 180 deg\n",
    "        ])\n",
    "    else:\n",
    "        # Just normalize LOS to x=0\n",
    "        df = df.with_columns([\n",
    "            (pl.col(\"x\") - pl.lit(los)).alias(\"x\"),\n",
    "        ])\n",
    "    return df\n",
    "\n",
    "# Apply transformation\n",
    "df_full_field  = transform_coordinates(df_with_frames, LOS, FLIP_ORIENTATION)\n",
    "\n",
    "# df: Filter the field so that it is within +/- 15 yards of the LOS. Essentially, the area of interest.\n",
    "df = df_full_field.filter((pl.col(\"x\") >= -15.0) & (pl.col(\"x\") <= 15.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CELL 5: Impute Missing Frames\n",
    "Manual inspection of the data shows that there are some missing frames in the data. To fix this and avoid downstream issues with rep detection, we will impute the missing frames via linear interpolation. (Meaning, we'll take the last known frame and the next known frame, and linearly step between them.) Other methods of imputation may be used, but were not explored. We'll only impute up to five missing frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before imputation: 1,100,217\n",
      "Imputed 183 missing frames\n",
      "Rows after imputation: 1,100,400\n"
     ]
    }
   ],
   "source": [
    "# Impute Missing Frames\n",
    "print(f\"Rows before imputation: {df.height:,}\")\n",
    "\n",
    "TRACKING_METRICS = [\"a\", \"dir\", \"sa\", \"dis\", \"s\", \"x\", \"y\", \"z\"]\n",
    "metrics_for_impute = [c for c in TRACKING_METRICS if c in df.columns]\n",
    "non_metric_cols = [c for c in df.columns if c not in metrics_for_impute + [\"frame_id\", \"ts\", \"parsed_ts\"]]\n",
    "\n",
    "# Build frame_id -> ts mapping\n",
    "frame_ts_map = dict(zip(frame_map[\"frame_id\"].to_list(), frame_map[\"ts\"].to_list()))\n",
    "\n",
    "rows_to_add = []\n",
    "for _, player_df in df.partition_by(\"id\", as_dict=True).items():\n",
    "    player_rows = player_df.sort(\"frame_id\").to_dicts()\n",
    "    for i in range(len(player_rows) - 1):\n",
    "        prev_row = player_rows[i]\n",
    "        next_row = player_rows[i + 1]\n",
    "        gap = next_row[\"frame_id\"] - prev_row[\"frame_id\"]\n",
    "        missing = gap - 1\n",
    "        # We will only impute up to 5 missing frames\n",
    "        if missing <= 0 or missing > 5:\n",
    "            continue\n",
    "        \n",
    "        # If set to False, it will impute the average of the previous and next frame across all missing frames\n",
    "        USE_LINEAR_INTERPOLATION = True\n",
    "        total_steps = next_row[\"frame_id\"] - prev_row[\"frame_id\"]\n",
    "\n",
    "        for fid in range(prev_row[\"frame_id\"] + 1, next_row[\"frame_id\"]):\n",
    "            ts_val = frame_ts_map.get(fid)\n",
    "            if ts_val is None:\n",
    "                continue\n",
    "\n",
    "            step = fid - prev_row[\"frame_id\"]\n",
    "\n",
    "            imputed_metrics = {}\n",
    "            for m in metrics_for_impute:\n",
    "                pv = prev_row.get(m)\n",
    "                nv = next_row.get(m)\n",
    "                if pv is None or nv is None:\n",
    "                    imputed_metrics[m] = pv if nv is None else nv if pv is None else None\n",
    "                elif USE_LINEAR_INTERPOLATION:\n",
    "                    imputed_metrics[m] = pv + (nv - pv) * (step / total_steps)\n",
    "                else:\n",
    "                    imputed_metrics[m] = (pv + nv) / 2\n",
    "\n",
    "            new_row = {col: prev_row.get(col) for col in non_metric_cols}\n",
    "            new_row[\"frame_id\"] = fid\n",
    "            new_row[\"ts\"] = ts_val\n",
    "            new_row[\"parsed_ts\"] = ts_val\n",
    "            new_row.update(imputed_metrics)\n",
    "            rows_to_add.append(new_row)\n",
    "\n",
    "if rows_to_add:\n",
    "    imputed_df = pl.DataFrame(rows_to_add)\n",
    "    if \"parsed_ts\" in imputed_df.columns:\n",
    "        imputed_df = imputed_df.with_columns(pl.col(\"parsed_ts\").str.to_datetime())\n",
    "\n",
    "    for col, dtype in df.schema.items():\n",
    "        if col not in imputed_df.columns:\n",
    "            imputed_df = imputed_df.with_columns(pl.lit(None, dtype=dtype).alias(col))\n",
    "\n",
    "    imputed_df = imputed_df.with_columns([\n",
    "        pl.col(col).cast(dtype, strict=False)\n",
    "        for col, dtype in df.schema.items()\n",
    "        if col in imputed_df.columns\n",
    "    ])\n",
    "    imputed_df = imputed_df.select(df.columns)\n",
    "    df = pl.concat([df, imputed_df], how=\"vertical\").sort([\"zebra_id\", \"frame_id\"])\n",
    "\n",
    "print(f\"Imputed {len(rows_to_add)} missing frames\")\n",
    "print(f\"Rows after imputation: {df.height:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CELL 6: FILTER TO REP PERIOD AND PLAYERS\n",
    "Based on the exploration visualization, set:\n",
    "1. `REP_PERIOD_START_TS` - Timestamp when OL-DL reps begin\n",
    "2. `REP_PERIOD_END_TS` - Timestamp when OL-DL reps end\n",
    "3. `olinemen` - List of OL jersey numbers\n",
    "4. `dlinemen` - List of DL jersey numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep period: 2024-01-27T17:14:06.100 to 2024-01-27T17:25:47.100\n",
      "Frame range: 49734 to 56744\n",
      "Rows in rep period: 160,352\n",
      "\n",
      "OL jerseys: ['75', '55', '72', '60', '54', '69', '71', '78', '77', '70', '73']\n",
      "DL jerseys: ['7', '6', '97', '85', '99', '9', '58', '92', '52', '8', '91']\n"
     ]
    }
   ],
   "source": [
    "# Configure these after using the visualization above \n",
    "# Or use prvoided timestamps from competition folder\n",
    "REP_PERIOD_START_TS = \"2024-01-27T17:14:06.100\" \n",
    "REP_PERIOD_END_TS = \"2024-01-27T17:25:47.100\"\n",
    "\n",
    "# OL and DL jersey numbers for this practice\n",
    "olinemen = [\"75\", \"55\", \"72\", \"60\", \"54\", \"69\", \"71\", \"78\", \"77\", \"70\", \"73\"]\n",
    "dlinemen = [\"7\", \"6\", \"97\", \"85\", \"99\", \"9\", \"58\", \"92\", \"52\", \"8\", \"91\"]\n",
    "\n",
    "# Filter to rep period\n",
    "df_reps = df.filter(\n",
    "    (pl.col(\"ts\") >= REP_PERIOD_START_TS) &\n",
    "    (pl.col(\"ts\") <= REP_PERIOD_END_TS)\n",
    ")\n",
    "\n",
    "# Add position flags\n",
    "df_reps = df_reps.with_columns([\n",
    "    pl.col(\"jersey_number\").is_in(olinemen).alias(\"is_olineman\"),\n",
    "    pl.col(\"jersey_number\").is_in(dlinemen).alias(\"is_dlineman\"),\n",
    "])\n",
    "\n",
    "print(f\"Rep period: {REP_PERIOD_START_TS} to {REP_PERIOD_END_TS}\")\n",
    "print(f\"Frame range: {df_reps['frame_id'].min()} to {df_reps['frame_id'].max()}\")\n",
    "print(f\"Rows in rep period: {df_reps.height:,}\")\n",
    "print(f\"\\nOL jerseys: {olinemen}\")\n",
    "print(f\"DL jerseys: {dlinemen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CELL 7: LOAD THE DETECTION ALGORITHM\n",
    "There are two main components of the detection algorithm:\n",
    "1. An targeted algorithm that identifies 1) identifies the OL-DL pair 2) marks the start of the rep and 3) marks the end of the rep. This is designed to work on a window of ~20 seconds that is segmented.\n",
    "2. A supra-algorithm that runs on the entire ~10 minute rep period. This identifies an individual 1-on-1 rep and then applies the targeted algorithm to each rep.\n",
    "\n",
    "#### Targeted Algorithm Components\n",
    " Core Pair Scoring\n",
    "\n",
    "  - For each OL/DL candidate pair, builds a time series by inner-joining on\n",
    "    frame_id and computing distance, distance change, and frame deltas.\n",
    "  - Engagement scoring uses distance dynamics: longest closing run, min\n",
    "    distance, sustained contact (<2.0), and “active close” frames (both speeds ≥\n",
    "    1.0).\n",
    "  - The primary engagement_score is the count of active close frames; other\n",
    "    metrics are used to tie-break.\n",
    "  - OL candidates can be filtered to those within OL_MAX_X_AT_TRIGGER yards of\n",
    "    LOS at the trigger frame.\n",
    "\n",
    "  Pair Selection\n",
    "\n",
    "  - Iterates all OL/DL combinations, computes scores, and selects the pair with\n",
    "    the highest engagement score.\n",
    "  - Ties are broken by earliest active closing frame, then earliest min-distance\n",
    "    frame, then earliest first-contact frame.\n",
    "  - If no valid pair exists, a ValueError is raised.\n",
    "\n",
    "  Rep Start Detection\n",
    "\n",
    "  - Finds the first DL crossing of CROSSING_X that stays above for\n",
    "    HOLD_FRAMES=10 consecutive frames.\n",
    "  - Looks back LOOKBACK_FRAMES=15 frames for a trigger where ol_a+dl_a ≥ 1.5 or\n",
    "    ol_s+dl_s ≥ 1.1; that becomes the start. (These values are based on looking at the data and finding reasonable\n",
    "    thresholds.)\n",
    "  - If no qualifying crossing exists, rep start defaults to the first frame in\n",
    "    the pair series.\n",
    "  - This assumes normalized orientation where DL moves in +x at the rep start.\n",
    "\n",
    "  Rep End Detection\n",
    "\n",
    "  - Starts searching SEARCH_DELAY_FRAMES=10 after the start.\n",
    "  - Ends the rep if either player shows a sustained retreat (x delta < -0.05 for\n",
    "    10 consecutive frames).\n",
    "  - Alternatively, ends on stagnation: |x| and |y| deltas < 0.01 for 3\n",
    "    consecutive frames.\n",
    "  - If neither condition triggers, the rep ends at the last available frame.\n",
    "\n",
    "##### Supra Algorithm Components\n",
    "  - find_next_dl_trigger locates the earliest frame where any DL crosses\n",
    "    TRIGGER_X from below to above.\n",
    "  - For each trigger, it defines a window [trigger - WINDOW_BEFORE_TRIGGER,\n",
    "    trigger + WINDOW_AFTER_TRIGGER].\n",
    "  - detect_rep runs pair selection and start/end logic; outer loop filters by\n",
    "    MIN_REP_DURATION.\n",
    "  - On success, the scan jumps ahead to rep_start + WINDOW_AFTER_TRIGGER; on\n",
    "    failure it advances by 10 frames.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rep detection helper functions loaded.\n",
      "Rep start/end detection functions loaded.\n",
      "  Using CROSSING_X = 0.5 (normalized coords)\n",
      "Main rep detection function loaded.\n",
      "\n",
      "All algorithm functions loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Rep Detection Algorithm Constants\n",
    "TRIGGER_X = 0.5             # DL crossing threshold for rep window trigger (normalized coords)\n",
    "CROSSING_X = 0.5            # DL crossing threshold for rep start detection (normalized coords)\n",
    "WINDOW_BEFORE_TRIGGER = 40  # 4.0 seconds\n",
    "WINDOW_AFTER_TRIGGER = 80   # 8.0 seconds\n",
    "MIN_REP_DURATION = 15       # 1.5 seconds (Can bump this up to 2.0 seconds)\n",
    "\n",
    "## OL proximity filter: only consider OLs within this distance of LOS at trigger frame\n",
    "## This helps prevent edge cases where the algorithm will pair a DL with an OL that is in the back of the endzone\n",
    "OL_MAX_X_AT_TRIGGER = 6\n",
    "\n",
    "# Functions\n",
    "def compute_pairwise_distance(x1: float, y1: float, x2: float, y2: float) -> float:\n",
    "    \"\"\"Euclidean distance between two points.\"\"\"\n",
    "    return np.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "\n",
    "def build_pair_timeseries(df_window: pl.DataFrame, ol_jersey: str, dl_jersey: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a timeseries DataFrame for an OL-DL pair with metrics from both players.\n",
    "    \"\"\"\n",
    "    ol_data = (\n",
    "        df_window\n",
    "        .filter(pl.col(\"jersey_number\") == ol_jersey)\n",
    "        .select([\"frame_id\", \"ts\", \"x\", \"y\", \"s\", \"a\"])\n",
    "        .rename({\"x\": \"ol_x\", \"y\": \"ol_y\", \"s\": \"ol_s\", \"a\": \"ol_a\"})\n",
    "    )\n",
    "    \n",
    "    dl_data = (\n",
    "        df_window\n",
    "        .filter(pl.col(\"jersey_number\") == dl_jersey)\n",
    "        .select([\"frame_id\", \"ts\", \"x\", \"y\", \"s\", \"a\"])\n",
    "        .rename({\"x\": \"dl_x\", \"y\": \"dl_y\", \"s\": \"dl_s\", \"a\": \"dl_a\"})\n",
    "    )\n",
    "    \n",
    "    pair_df = ol_data.join(dl_data.drop(\"ts\"), on=\"frame_id\", how=\"inner\")\n",
    "    \n",
    "    if pair_df.height == 0:\n",
    "        return pair_df\n",
    "    \n",
    "    pair_df = pair_df.sort(\"frame_id\")\n",
    "    \n",
    "    pair_df = pair_df.with_columns(\n",
    "        (((pl.col(\"ol_x\") - pl.col(\"dl_x\"))**2 + (pl.col(\"ol_y\") - pl.col(\"dl_y\"))**2).sqrt())\n",
    "        .alias(\"pairwise_distance\")\n",
    "    )\n",
    "    \n",
    "    pair_df = pair_df.with_columns(\n",
    "        (pl.col(\"pairwise_distance\") - pl.col(\"pairwise_distance\").shift(1))\n",
    "        .alias(\"distance_change\")\n",
    "    )\n",
    "    \n",
    "    pair_df = pair_df.with_columns(\n",
    "        (pl.col(\"frame_id\") - pl.col(\"frame_id\").shift(1))\n",
    "        .alias(\"frame_delta\")\n",
    "    )\n",
    "    \n",
    "    return pair_df\n",
    "\n",
    "def score_pair_engagement(pair_df: pl.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Score how likely this OL-DL pair is the engaged pair for the rep.\n",
    "    \"\"\"\n",
    "    if pair_df.height < 5:\n",
    "        return {\n",
    "            \"engagement_score\": 0,\n",
    "            \"min_distance\": 999,\n",
    "            \"closing_frames\": 0,\n",
    "            \"sustained_contact_frames\": 0,\n",
    "            \"close_duration\": 0,\n",
    "            \"activity_score\": 0,\n",
    "            \"active_close_frames\": 0,\n",
    "            \"min_distance_idx\": 0,\n",
    "        }\n",
    "\n",
    "    distances = pair_df[\"pairwise_distance\"].to_numpy()\n",
    "    distance_changes = pair_df[\"distance_change\"].to_numpy()\n",
    "    frame_deltas = pair_df[\"frame_delta\"].to_numpy()\n",
    "    ol_accels = pair_df[\"ol_a\"].to_numpy()\n",
    "    dl_accels = pair_df[\"dl_a\"].to_numpy()\n",
    "    ol_speeds = pair_df[\"ol_s\"].to_numpy()\n",
    "    dl_speeds = pair_df[\"dl_s\"].to_numpy()\n",
    "\n",
    "    min_distance = float(np.nanmin(distances))\n",
    "    min_distance_idx = int(np.nanargmin(distances))\n",
    "\n",
    "    max_closing_run = 0\n",
    "    current_run = 0\n",
    "    for i in range(1, len(distance_changes)):\n",
    "        dc = distance_changes[i]\n",
    "        fd = frame_deltas[i]\n",
    "        is_consecutive = fd is not None and not np.isnan(fd) and fd == 1\n",
    "        is_closing = dc is not None and not np.isnan(dc) and dc < -0.01\n",
    "\n",
    "        if is_consecutive and is_closing:\n",
    "            current_run += 1\n",
    "            max_closing_run = max(max_closing_run, current_run)\n",
    "        else:\n",
    "            current_run = 0\n",
    "    closing_frames = max_closing_run\n",
    "\n",
    "    CONTACT_THRESHOLD = 2.0\n",
    "    sustained_contact_frames = int(np.sum(distances < CONTACT_THRESHOLD))\n",
    "    close_duration = int(np.sum(distances < 2.0))\n",
    "\n",
    "    active_close_mask = (distances < 2.0) & (ol_speeds >= 1.0) & (dl_speeds >= 1.0)\n",
    "    active_close_frames = int(np.sum(active_close_mask))\n",
    "\n",
    "    closing_mask = np.zeros(len(distance_changes) - 1, dtype=bool)\n",
    "    for i in range(1, len(distance_changes)):\n",
    "        dc = distance_changes[i]\n",
    "        fd = frame_deltas[i]\n",
    "        is_consecutive = fd is not None and not np.isnan(fd) and fd == 1\n",
    "        is_closing = dc is not None and not np.isnan(dc) and dc < -0.01\n",
    "        if is_consecutive and is_closing:\n",
    "            closing_mask[i - 1] = True\n",
    "\n",
    "    if np.any(closing_mask):\n",
    "        activity_score = float(np.mean(ol_accels[1:][closing_mask] + dl_accels[1:][closing_mask]))\n",
    "    else:\n",
    "        activity_score = 0.0\n",
    "\n",
    "    engagement_score = float(active_close_frames)\n",
    "\n",
    "    return {\n",
    "        \"engagement_score\": engagement_score,\n",
    "        \"min_distance\": min_distance,\n",
    "        \"min_distance_idx\": min_distance_idx,\n",
    "        \"closing_frames\": closing_frames,\n",
    "        \"sustained_contact_frames\": sustained_contact_frames,\n",
    "        \"close_duration\": close_duration,\n",
    "        \"activity_score\": activity_score,\n",
    "        \"active_close_frames\": active_close_frames,\n",
    "    }\n",
    "\n",
    "def identify_ol_dl_pair(df_window: pl.DataFrame, excluded_ol_jerseys: list = None, trigger_frame: int = None) -> tuple:\n",
    "    \"\"\"\n",
    "    Identify the OL-DL pair engaged in the rep.\n",
    "    \n",
    "    Parameters:\n",
    "        df_window: DataFrame containing the rep window data\n",
    "        excluded_ol_jerseys: List of OL jerseys to exclude from consideration\n",
    "        trigger_frame: Frame when DL crossed TRIGGER_X (used to filter OLs by position)\n",
    "    \"\"\"\n",
    "    if excluded_ol_jerseys is None:\n",
    "        excluded_ol_jerseys = []\n",
    "    \n",
    "    ol_jerseys = (\n",
    "        df_window\n",
    "        .filter(pl.col(\"is_olineman\") == True)\n",
    "        .select(\"jersey_number\")\n",
    "        .unique()\n",
    "        [\"jersey_number\"]\n",
    "        .to_list()\n",
    "    )\n",
    "    \n",
    "    # Filter OL candidates to those within OL_MAX_X_AT_TRIGGER yards of LOS at trigger frame\n",
    "    if trigger_frame is not None:\n",
    "        ol_jerseys_near_los = []\n",
    "        for ol_j in ol_jerseys:\n",
    "            if ol_j in excluded_ol_jerseys:\n",
    "                continue\n",
    "            # Get OL position at trigger frame\n",
    "            ol_at_trigger = df_window.filter(\n",
    "                (pl.col(\"jersey_number\") == ol_j) &\n",
    "                (pl.col(\"frame_id\") == trigger_frame)\n",
    "            )\n",
    "            if ol_at_trigger.height > 0:\n",
    "                x_at_trigger = ol_at_trigger.select(\"x\").item()\n",
    "                if x_at_trigger is not None and x_at_trigger <= OL_MAX_X_AT_TRIGGER:\n",
    "                    ol_jerseys_near_los.append(ol_j)\n",
    "        ol_jerseys = ol_jerseys_near_los\n",
    "    else:\n",
    "        # Fallback: just exclude the excluded jerseys\n",
    "        ol_jerseys = [j for j in ol_jerseys if j not in excluded_ol_jerseys]\n",
    "    \n",
    "    dl_jerseys = (\n",
    "        df_window\n",
    "        .filter(pl.col(\"is_dlineman\") == True)\n",
    "        .select(\"jersey_number\")\n",
    "        .unique()\n",
    "        [\"jersey_number\"]\n",
    "        .to_list()\n",
    "    )\n",
    "    \n",
    "    if len(ol_jerseys) == 0 or len(dl_jerseys) == 0:\n",
    "        raise ValueError(\"No OL or DL players found in window (or all OL excluded/filtered by position)\")\n",
    "    \n",
    "    best_score = -1\n",
    "    best_pair = (None, None)\n",
    "    best_pair_df = None\n",
    "    best_info = None\n",
    "\n",
    "    TIEBREAK_SCORE_EPS = 0.02\n",
    "    CONTACT_THRESHOLD = 1.5\n",
    "    ACTIVE_CLOSING_THRESHOLD = -0.005\n",
    "    MIN_ACTIVITY_SPEED = 0.3\n",
    "    MIN_ACTIVITY_ACCEL = 0.5\n",
    "\n",
    "    for ol_j in ol_jerseys:\n",
    "        for dl_j in dl_jerseys:\n",
    "            pair_df = build_pair_timeseries(df_window, ol_j, dl_j)\n",
    "            if pair_df.height < 5:\n",
    "                continue\n",
    "            \n",
    "            info = score_pair_engagement(pair_df)\n",
    "\n",
    "            frame_ids = pair_df[\"frame_id\"].to_numpy()\n",
    "            distances = pair_df[\"pairwise_distance\"].to_numpy()\n",
    "            distance_changes = pair_df[\"distance_change\"].to_numpy()\n",
    "            frame_deltas = pair_df[\"frame_delta\"].to_numpy()\n",
    "            ol_speeds = pair_df[\"ol_s\"].to_numpy()\n",
    "            dl_speeds = pair_df[\"dl_s\"].to_numpy()\n",
    "            ol_accels = pair_df[\"ol_a\"].to_numpy()\n",
    "            dl_accels = pair_df[\"dl_a\"].to_numpy()\n",
    "            min_idx = info.get(\"min_distance_idx\", 0)\n",
    "            min_frame = int(frame_ids[min_idx]) if len(frame_ids) > min_idx else int(frame_ids[0])\n",
    "            first_close_frame = None\n",
    "            if len(distances) > 0:\n",
    "                close_idx = np.where(distances < CONTACT_THRESHOLD)[0]\n",
    "                if close_idx.size > 0:\n",
    "                    first_close_frame = int(frame_ids[close_idx[0]])\n",
    "\n",
    "            first_active_closing_frame = None\n",
    "            for i in range(1, len(distance_changes)):\n",
    "                dc = distance_changes[i]\n",
    "                fd = frame_deltas[i]\n",
    "                if dc is None or np.isnan(dc) or fd is None or np.isnan(fd) or fd != 1:\n",
    "                    continue\n",
    "                if dc < ACTIVE_CLOSING_THRESHOLD:\n",
    "                    max_speed = max(ol_speeds[i], dl_speeds[i])\n",
    "                    max_accel = max(ol_accels[i], dl_accels[i])\n",
    "\n",
    "                    if max_speed >= MIN_ACTIVITY_SPEED or max_accel >= MIN_ACTIVITY_ACCEL:\n",
    "                        first_active_closing_frame = int(frame_ids[i])\n",
    "                        break\n",
    "\n",
    "            info[\"min_distance_frame\"] = min_frame\n",
    "            info[\"first_close_frame\"] = first_close_frame\n",
    "            info[\"first_active_closing_frame\"] = first_active_closing_frame\n",
    "            \n",
    "            score = info[\"engagement_score\"]\n",
    "            if score > best_score + TIEBREAK_SCORE_EPS:\n",
    "                best_score = score\n",
    "                best_pair = (ol_j, dl_j)\n",
    "                best_pair_df = pair_df\n",
    "                best_info = info\n",
    "            elif best_info is None or abs(score - best_score) <= TIEBREAK_SCORE_EPS:\n",
    "                cand_active = info.get(\"first_active_closing_frame\")\n",
    "                best_active = best_info.get(\"first_active_closing_frame\") if best_info else None\n",
    "                cand_min = info.get(\"min_distance_frame\")\n",
    "                best_min = best_info.get(\"min_distance_frame\") if best_info else None\n",
    "                cand_first = info.get(\"first_close_frame\")\n",
    "                best_first = best_info.get(\"first_close_frame\") if best_info else None\n",
    "\n",
    "                prefer = False\n",
    "                if cand_active is not None and best_active is not None and cand_active != best_active:\n",
    "                    prefer = cand_active < best_active\n",
    "                elif cand_min is not None and best_min is not None and cand_min != best_min:\n",
    "                    prefer = cand_min < best_min\n",
    "                elif cand_first is not None and best_first is not None and cand_first != best_first:\n",
    "                    prefer = cand_first < best_first\n",
    "\n",
    "                if best_info is None or prefer:\n",
    "                    best_score = score\n",
    "                    best_pair = (ol_j, dl_j)\n",
    "                    best_pair_df = pair_df\n",
    "                    best_info = info\n",
    "    \n",
    "    if best_pair[0] is None:\n",
    "        raise ValueError(\"Could not identify engaged OL-DL pair\")\n",
    "    \n",
    "    return best_pair[0], best_pair[1], best_pair_df, best_info\n",
    "\n",
    "print(\"Rep detection helper functions loaded.\")\n",
    "\n",
    "# Rep Start Detection - Uses global CROSSING_X\n",
    "def detect_rep_start(pair_df: pl.DataFrame, min_distance_idx: int = None, df_window: pl.DataFrame = None, ol_jersey: str = None) -> int:\n",
    "    \"\"\"\n",
    "    Detect rep start using DL crossing CROSSING_X with lookback for acceleration trigger.\n",
    "    Uses global CROSSING_X (normalized to 0.5 for LOS at x=0).\n",
    "    \"\"\"\n",
    "    if pair_df.height == 0:\n",
    "        return 0\n",
    "    pair_df = pair_df.sort(\"frame_id\")\n",
    "    frame_ids = pair_df[\"frame_id\"].to_numpy()\n",
    "    dl_x = pair_df[\"dl_x\"].to_numpy()\n",
    "    ol_a = pair_df[\"ol_a\"].to_numpy()\n",
    "    dl_a = pair_df[\"dl_a\"].to_numpy()\n",
    "    ol_s = pair_df[\"ol_s\"].to_numpy()\n",
    "    dl_s = pair_df[\"dl_s\"].to_numpy()\n",
    "    frame_deltas = np.concatenate([[np.nan], np.diff(frame_ids)])\n",
    "    n = len(frame_ids)\n",
    "    \n",
    "    # Use global CROSSING_X (set in Cell 2)\n",
    "    HOLD_FRAMES = 10\n",
    "    LOOKBACK_FRAMES = 15\n",
    "    ACCEL_SUM_THRESHOLD = 1.5\n",
    "    SPEED_SUM_THRESHOLD = 1.1\n",
    "    \n",
    "    crossing_idx = None\n",
    "    for i in range(0, n - HOLD_FRAMES + 1):\n",
    "        if dl_x[i] <= CROSSING_X:\n",
    "            continue\n",
    "        if i > 0 and dl_x[i-1] > CROSSING_X:\n",
    "            continue\n",
    "        run_ok = True\n",
    "        for j in range(HOLD_FRAMES):\n",
    "            idx = i + j\n",
    "            if dl_x[idx] <= CROSSING_X:\n",
    "                run_ok = False\n",
    "                break\n",
    "            if j > 0:\n",
    "                fd = frame_deltas[idx]\n",
    "                if fd is None or np.isnan(fd) or fd != 1:\n",
    "                    run_ok = False\n",
    "                    break\n",
    "        if run_ok:\n",
    "            crossing_idx = i\n",
    "            break\n",
    "    \n",
    "    if crossing_idx is None:\n",
    "        return int(frame_ids[0])\n",
    "    \n",
    "    lookback_start = max(0, crossing_idx - LOOKBACK_FRAMES)\n",
    "    \n",
    "    for i in range(lookback_start, crossing_idx + 1):\n",
    "        accel_sum = ol_a[i] + dl_a[i]\n",
    "        speed_sum = ol_s[i] + dl_s[i]\n",
    "        if not np.isnan(accel_sum) and ((accel_sum >= ACCEL_SUM_THRESHOLD) | (speed_sum >= SPEED_SUM_THRESHOLD)):\n",
    "            return int(frame_ids[i])\n",
    "    \n",
    "    return int(frame_ids[crossing_idx])\n",
    "\n",
    "def detect_rep_end(pair_df: pl.DataFrame, rep_start_frame: int) -> int:\n",
    "    \"\"\"\n",
    "    Rep End Detection: LOS Retreat OR Stagnation Rule\n",
    "    \"\"\"\n",
    "    SEARCH_DELAY_FRAMES = 10\n",
    "    X_DECREASE_THRESHOLD = -0.05\n",
    "    CONSECUTIVE_FRAMES = 10\n",
    "    STAGNATION_THRESHOLD = 0.01\n",
    "    STAGNATION_FRAMES = 3\n",
    "\n",
    "    search_start_frame = rep_start_frame + SEARCH_DELAY_FRAMES\n",
    "    pair_after_delay = pair_df.filter(pl.col(\"frame_id\") >= search_start_frame)\n",
    "\n",
    "    min_frames_needed = min(CONSECUTIVE_FRAMES, STAGNATION_FRAMES)\n",
    "    if pair_after_delay.height < min_frames_needed:\n",
    "        return int(pair_df[\"frame_id\"].max())\n",
    "\n",
    "    pair_after_delay = pair_after_delay.sort(\"frame_id\")\n",
    "    pair_after_delay = pair_after_delay.with_columns([\n",
    "        (pl.col(\"frame_id\") - pl.col(\"frame_id\").shift(1)).alias(\"frame_delta\"),\n",
    "        (pl.col(\"ol_x\") - pl.col(\"ol_x\").shift(1)).alias(\"ol_x_delta\"),\n",
    "        (pl.col(\"ol_y\") - pl.col(\"ol_y\").shift(1)).alias(\"ol_y_delta\"),\n",
    "        (pl.col(\"dl_x\") - pl.col(\"dl_x\").shift(1)).alias(\"dl_x_delta\"),\n",
    "        (pl.col(\"dl_y\") - pl.col(\"dl_y\").shift(1)).alias(\"dl_y_delta\")\n",
    "    ])\n",
    "\n",
    "    frame_ids = pair_after_delay[\"frame_id\"].to_numpy()\n",
    "    frame_deltas = pair_after_delay[\"frame_delta\"].to_numpy()\n",
    "    ol_x_deltas = pair_after_delay[\"ol_x_delta\"].to_numpy()\n",
    "    ol_y_deltas = pair_after_delay[\"ol_y_delta\"].to_numpy()\n",
    "    dl_x_deltas = pair_after_delay[\"dl_x_delta\"].to_numpy()\n",
    "    dl_y_deltas = pair_after_delay[\"dl_y_delta\"].to_numpy()\n",
    "    n = len(frame_ids)\n",
    "\n",
    "    for i in range(1, n):\n",
    "        # Condition A: LOS Retreat\n",
    "        if i <= n - CONSECUTIVE_FRAMES:\n",
    "            ol_retreat_run = True\n",
    "            for j in range(CONSECUTIVE_FRAMES):\n",
    "                idx = i + j\n",
    "                if idx >= n:\n",
    "                    ol_retreat_run = False\n",
    "                    break\n",
    "                fd = frame_deltas[idx]\n",
    "                is_consecutive = fd is not None and not np.isnan(fd) and fd == 1\n",
    "                ol_xd = ol_x_deltas[idx]\n",
    "                ol_retreating = ol_xd is not None and not np.isnan(ol_xd) and ol_xd < X_DECREASE_THRESHOLD\n",
    "                if not (is_consecutive and ol_retreating):\n",
    "                    ol_retreat_run = False\n",
    "                    break\n",
    "            if ol_retreat_run:\n",
    "                return int(frame_ids[i])\n",
    "\n",
    "            dl_retreat_run = True\n",
    "            for j in range(CONSECUTIVE_FRAMES):\n",
    "                idx = i + j\n",
    "                if idx >= n:\n",
    "                    dl_retreat_run = False\n",
    "                    break\n",
    "                fd = frame_deltas[idx]\n",
    "                is_consecutive = fd is not None and not np.isnan(fd) and fd == 1\n",
    "                dl_xd = dl_x_deltas[idx]\n",
    "                dl_retreating = dl_xd is not None and not np.isnan(dl_xd) and dl_xd < X_DECREASE_THRESHOLD\n",
    "                if not (is_consecutive and dl_retreating):\n",
    "                    dl_retreat_run = False\n",
    "                    break\n",
    "            if dl_retreat_run:\n",
    "                return int(frame_ids[i])\n",
    "\n",
    "        # Condition B: Stagnation\n",
    "        if i <= n - STAGNATION_FRAMES:\n",
    "            ol_stagnant_run = True\n",
    "            for j in range(STAGNATION_FRAMES):\n",
    "                idx = i + j\n",
    "                if idx >= n:\n",
    "                    ol_stagnant_run = False\n",
    "                    break\n",
    "                fd = frame_deltas[idx]\n",
    "                is_consecutive = fd is not None and not np.isnan(fd) and fd == 1\n",
    "                ol_xd = ol_x_deltas[idx]\n",
    "                ol_yd = ol_y_deltas[idx]\n",
    "                ol_x_stagnant = ol_xd is not None and not np.isnan(ol_xd) and abs(ol_xd) < STAGNATION_THRESHOLD\n",
    "                ol_y_stagnant = ol_yd is not None and not np.isnan(ol_yd) and abs(ol_yd) < STAGNATION_THRESHOLD\n",
    "                ol_is_stagnant = ol_x_stagnant and ol_y_stagnant\n",
    "                if not (is_consecutive and ol_is_stagnant):\n",
    "                    ol_stagnant_run = False\n",
    "                    break\n",
    "            if ol_stagnant_run:\n",
    "                return int(frame_ids[i])\n",
    "\n",
    "            dl_stagnant_run = True\n",
    "            for j in range(STAGNATION_FRAMES):\n",
    "                idx = i + j\n",
    "                if idx >= n:\n",
    "                    dl_stagnant_run = False\n",
    "                    break\n",
    "                fd = frame_deltas[idx]\n",
    "                is_consecutive = fd is not None and not np.isnan(fd) and fd == 1\n",
    "                dl_xd = dl_x_deltas[idx]\n",
    "                dl_yd = dl_y_deltas[idx]\n",
    "                dl_x_stagnant = dl_xd is not None and not np.isnan(dl_xd) and abs(dl_xd) < STAGNATION_THRESHOLD\n",
    "                dl_y_stagnant = dl_yd is not None and not np.isnan(dl_yd) and abs(dl_yd) < STAGNATION_THRESHOLD\n",
    "                dl_is_stagnant = dl_x_stagnant and dl_y_stagnant\n",
    "                if not (is_consecutive and dl_is_stagnant):\n",
    "                    dl_stagnant_run = False\n",
    "                    break\n",
    "            if dl_stagnant_run:\n",
    "                return int(frame_ids[i])\n",
    "\n",
    "    return int(frame_ids[-1])\n",
    "\n",
    "print(\"Rep start/end detection functions loaded.\")\n",
    "print(f\"  Using CROSSING_X = {CROSSING_X} (normalized coords)\")\n",
    "\n",
    "def detect_rep(df_window: pl.DataFrame, window_start: int, window_end: int, rep_number: int = 0, trigger_frame: int = None) -> dict:\n",
    "    \"\"\"Main rep detection function with fallback loop.\n",
    "    \n",
    "    Parameters:\n",
    "        df_window: DataFrame containing the rep window data\n",
    "        window_start: Start frame of the window\n",
    "        window_end: End frame of the window\n",
    "        rep_number: Rep number for labeling\n",
    "        trigger_frame: Frame when DL crossed TRIGGER_X (passed to identify_ol_dl_pair)\n",
    "    \"\"\"\n",
    "    MIN_REP_DURATION_LOCAL = 0\n",
    "    MAX_RETRIES = 3\n",
    "    \n",
    "    excluded_ol_jerseys = []\n",
    "    best_result = None\n",
    "    best_rep_duration = 0\n",
    "    \n",
    "    for attempt in range(MAX_RETRIES + 1):\n",
    "        try:\n",
    "            ol_jersey, dl_jersey, pair_df, engagement_info = identify_ol_dl_pair(\n",
    "                df_window, excluded_ol_jerseys=excluded_ol_jerseys, trigger_frame=trigger_frame\n",
    "            )\n",
    "            \n",
    "            rep_start_frame = detect_rep_start(pair_df, engagement_info.get(\"min_distance_idx\"), df_window, ol_jersey)\n",
    "            rep_end_frame = detect_rep_end(pair_df, rep_start_frame)\n",
    "            \n",
    "            rep_duration = rep_end_frame - rep_start_frame\n",
    "            \n",
    "            start_ts_row = pair_df.filter(pl.col(\"frame_id\") == rep_start_frame)\n",
    "            end_ts_row = pair_df.filter(pl.col(\"frame_id\") == rep_end_frame)\n",
    "            start_ts = start_ts_row[\"ts\"][0] if start_ts_row.height > 0 else None\n",
    "            end_ts = end_ts_row[\"ts\"][0] if end_ts_row.height > 0 else None\n",
    "            \n",
    "            result = {\n",
    "                \"window_start\": window_start,\n",
    "                \"window_end\": window_end,\n",
    "                \"ol_jersey\": ol_jersey,\n",
    "                \"dl_jersey\": dl_jersey,\n",
    "                \"rep_start_frame\": rep_start_frame,\n",
    "                \"rep_end_frame\": rep_end_frame,\n",
    "                \"start_ts\": start_ts,\n",
    "                \"end_ts\": end_ts,\n",
    "                \"engagement_info\": engagement_info,\n",
    "                \"pair_timeseries\": pair_df,\n",
    "                \"rep_number\": rep_number,\n",
    "                \"retry_attempt\": attempt,\n",
    "                \"excluded_ol_jerseys\": list(excluded_ol_jerseys)\n",
    "            }\n",
    "            \n",
    "            if rep_duration > best_rep_duration:\n",
    "                best_rep_duration = rep_duration\n",
    "                best_result = result\n",
    "            \n",
    "            if rep_duration >= MIN_REP_DURATION_LOCAL:\n",
    "                return result\n",
    "            \n",
    "            if attempt < MAX_RETRIES:\n",
    "                excluded_ol_jerseys.append(ol_jersey)\n",
    "            \n",
    "        except ValueError as e:\n",
    "            if best_result is not None:\n",
    "                return best_result\n",
    "            raise e\n",
    "    \n",
    "    return best_result\n",
    "\n",
    "print(\"Main rep detection function loaded.\")\n",
    "\n",
    "# DL Trigger Detection - Uses global TRIGGER_X\n",
    "def find_next_dl_trigger(df: pl.DataFrame, start_frame: int, end_frame: int = None) -> int | None:\n",
    "    \"\"\"Find next frame where ANY DL crosses TRIGGER_X in increasing x direction.\"\"\"\n",
    "    dl_df = df.filter(pl.col(\"is_dlineman\") == True)\n",
    "    \n",
    "    if end_frame is not None:\n",
    "        dl_df = dl_df.filter(\n",
    "            (pl.col(\"frame_id\") >= start_frame) &\n",
    "            (pl.col(\"frame_id\") <= end_frame)\n",
    "        )\n",
    "    else:\n",
    "        dl_df = dl_df.filter(pl.col(\"frame_id\") >= start_frame)\n",
    "    \n",
    "    if dl_df.height == 0:\n",
    "        return None\n",
    "    \n",
    "    dl_with_prev = (\n",
    "        dl_df\n",
    "        .sort([\"jersey_number\", \"frame_id\"])\n",
    "        .with_columns(\n",
    "            pl.col(\"x\").shift(1).over(\"jersey_number\").alias(\"x_prev\")\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Use global TRIGGER_X\n",
    "    crossings = dl_with_prev.filter(\n",
    "        (pl.col(\"x_prev\").is_not_null()) &\n",
    "        (pl.col(\"x_prev\") < TRIGGER_X) &\n",
    "        (pl.col(\"x\") >= TRIGGER_X)\n",
    "    )\n",
    "    \n",
    "    if crossings.height == 0:\n",
    "        return None\n",
    "    \n",
    "    earliest_frame = crossings[\"frame_id\"].min()\n",
    "    return int(earliest_frame)\n",
    "\n",
    "def run_supra_algorithm(df: pl.DataFrame, start_frame: int, end_frame: int, verbose: bool = True) -> list:\n",
    "    \"\"\"Main supra-algorithm that scans through the practice period and detects all reps.\"\"\"\n",
    "    results = []\n",
    "    rep_number = 1\n",
    "    current_scan_position = start_frame\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Starting supra-algorithm scan from frame {start_frame} to {end_frame}\")\n",
    "        print(f\"Trigger X: {TRIGGER_X}, Window: [-{WINDOW_BEFORE_TRIGGER}, +{WINDOW_AFTER_TRIGGER}]\")\n",
    "        print(f\"OL position filter: x <= {OL_MAX_X_AT_TRIGGER} at trigger frame\")\n",
    "        print(\"=\" * 70)\n",
    "    \n",
    "    while current_scan_position < end_frame:\n",
    "        trigger_frame = find_next_dl_trigger(df, current_scan_position, end_frame)\n",
    "        \n",
    "        if trigger_frame is None:\n",
    "            if verbose:\n",
    "                print(f\"No more triggers found after frame {current_scan_position}\")\n",
    "            break\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nRep {rep_number}: Trigger at frame {trigger_frame}\")\n",
    "        \n",
    "        window_start = max(start_frame, trigger_frame - WINDOW_BEFORE_TRIGGER)\n",
    "        window_end = min(end_frame, trigger_frame + WINDOW_AFTER_TRIGGER)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Window: [{window_start}, {window_end}]\")\n",
    "        \n",
    "        df_window = df.filter(\n",
    "            (pl.col(\"frame_id\") >= window_start) &\n",
    "            (pl.col(\"frame_id\") <= window_end)\n",
    "        )\n",
    "        \n",
    "        if df_window.height == 0:\n",
    "            if verbose:\n",
    "                print(f\"  Empty window, skipping\")\n",
    "            current_scan_position = trigger_frame + 10\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            result = detect_rep(df_window, window_start, window_end, rep_number, trigger_frame=trigger_frame)\n",
    "            \n",
    "            if result is not None:\n",
    "                rep_duration = result['rep_end_frame'] - result['rep_start_frame']\n",
    "                \n",
    "                if rep_duration >= MIN_REP_DURATION:\n",
    "                    results.append(result)\n",
    "                    if verbose:\n",
    "                        print(f\"  Detected: OL {result['ol_jersey']} vs DL {result['dl_jersey']}\")\n",
    "                        print(f\"  Rep frames: {result['rep_start_frame']} - {result['rep_end_frame']} ({rep_duration} frames)\")\n",
    "                    \n",
    "                    rep_number += 1\n",
    "                    current_scan_position = result['rep_start_frame'] + WINDOW_AFTER_TRIGGER\n",
    "                else:\n",
    "                    if verbose:\n",
    "                        print(f\"  Rep too short ({rep_duration} frames < {MIN_REP_DURATION}), skipping\")\n",
    "                    current_scan_position = trigger_frame + 10\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"  No valid rep detected, skipping\")\n",
    "                current_scan_position = trigger_frame + 10\n",
    "                \n",
    "        except ValueError as e:\n",
    "            if verbose:\n",
    "                print(f\"  Error: {e}, skipping\")\n",
    "            current_scan_position = trigger_frame + 10\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(f\"Supra-algorithm complete. Detected {len(results)} reps.\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def build_output_dataframe(results: list, jersey_to_zebra: dict) -> pl.DataFrame:\n",
    "    \"\"\"Convert results list to summary DataFrame.\"\"\"\n",
    "    if not results:\n",
    "        return pl.DataFrame({\n",
    "            'rep_number': [], 'rep_start_frame': [], 'rep_end_frame': [],\n",
    "            'ol_jersey': [], 'dl_jersey': [], 'ol_zebra_id': [], 'dl_zebra_id': [],\n",
    "            'start_ts': [], 'end_ts': [], 'duration_frames': [], 'duration_seconds': [],\n",
    "        })\n",
    "\n",
    "    rows = []\n",
    "    for r in results:\n",
    "        duration_frames = r['rep_end_frame'] - r['rep_start_frame'] + 1  # +1 for inclusive count\n",
    "        rows.append({\n",
    "            'rep_number': r['rep_number'],\n",
    "            'rep_start_frame': r['rep_start_frame'],\n",
    "            'rep_end_frame': r['rep_end_frame'],\n",
    "            'ol_jersey': r['ol_jersey'],\n",
    "            'dl_jersey': r['dl_jersey'],\n",
    "            'ol_zebra_id': jersey_to_zebra.get(r['ol_jersey']),\n",
    "            'dl_zebra_id': jersey_to_zebra.get(r['dl_jersey']),\n",
    "            'start_ts': r['start_ts'],\n",
    "            'end_ts': r['end_ts'],\n",
    "            'duration_frames': duration_frames,\n",
    "            'duration_seconds': duration_frames * 0.1,\n",
    "        })\n",
    "\n",
    "    return pl.DataFrame(rows)\n",
    "\n",
    "print(\"\\nAll algorithm functions loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CELL 8: RUN THE ALGORITHM\n",
    "Let it rip!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting supra-algorithm scan from frame 49734 to 56744\n",
      "Trigger X: 0.5, Window: [-40, +80]\n",
      "OL position filter: x <= 6 at trigger frame\n",
      "======================================================================\n",
      "\n",
      "Rep 1: Trigger at frame 49824\n",
      "  Window: [49784, 49904]\n",
      "  Detected: OL 71 vs DL 91\n",
      "  Rep frames: 49815 - 49842 (27 frames)\n",
      "\n",
      "Rep 2: Trigger at frame 50039\n",
      "  Window: [49999, 50119]\n",
      "  Detected: OL 71 vs DL 91\n",
      "  Rep frames: 50029 - 50073 (44 frames)\n",
      "\n",
      "Rep 3: Trigger at frame 50177\n",
      "  Window: [50137, 50257]\n",
      "  Detected: OL 69 vs DL 8\n",
      "  Rep frames: 50163 - 50205 (42 frames)\n",
      "\n",
      "Rep 4: Trigger at frame 50353\n",
      "  Window: [50313, 50433]\n",
      "  Detected: OL 69 vs DL 8\n",
      "  Rep frames: 50342 - 50375 (33 frames)\n",
      "\n",
      "Rep 5: Trigger at frame 50479\n",
      "  Window: [50439, 50559]\n",
      "  Detected: OL 54 vs DL 52\n",
      "  Rep frames: 50465 - 50502 (37 frames)\n",
      "\n",
      "Rep 6: Trigger at frame 50633\n",
      "  Window: [50593, 50713]\n",
      "  Detected: OL 54 vs DL 52\n",
      "  Rep frames: 50621 - 50665 (44 frames)\n",
      "\n",
      "Rep 7: Trigger at frame 50878\n",
      "  Window: [50838, 50958]\n",
      "  Detected: OL 73 vs DL 92\n",
      "  Rep frames: 50864 - 50908 (44 frames)\n",
      "\n",
      "Rep 8: Trigger at frame 51053\n",
      "  Window: [51013, 51133]\n",
      "  Detected: OL 73 vs DL 92\n",
      "  Rep frames: 51044 - 51077 (33 frames)\n",
      "\n",
      "Rep 9: Trigger at frame 51299\n",
      "  Window: [51259, 51379]\n",
      "  Detected: OL 77 vs DL 58\n",
      "  Rep frames: 51288 - 51319 (31 frames)\n",
      "\n",
      "Rep 10: Trigger at frame 51533\n",
      "  Window: [51493, 51613]\n",
      "  Detected: OL 77 vs DL 58\n",
      "  Rep frames: 51522 - 51556 (34 frames)\n",
      "\n",
      "Rep 11: Trigger at frame 51761\n",
      "  Window: [51721, 51841]\n",
      "  Detected: OL 60 vs DL 99\n",
      "  Rep frames: 51749 - 51779 (30 frames)\n",
      "\n",
      "Rep 12: Trigger at frame 51900\n",
      "  Window: [51860, 51980]\n",
      "  Detected: OL 60 vs DL 99\n",
      "  Rep frames: 51890 - 51932 (42 frames)\n",
      "\n",
      "Rep 13: Trigger at frame 52086\n",
      "  Window: [52046, 52166]\n",
      "  Detected: OL 60 vs DL 99\n",
      "  Rep frames: 52075 - 52114 (39 frames)\n",
      "\n",
      "Rep 14: Trigger at frame 52244\n",
      "  Window: [52204, 52324]\n",
      "  Detected: OL 60 vs DL 85\n",
      "  Rep frames: 52233 - 52264 (31 frames)\n",
      "\n",
      "Rep 15: Trigger at frame 52408\n",
      "  Window: [52368, 52488]\n",
      "  Detected: OL 72 vs DL 85\n",
      "  Rep frames: 52403 - 52428 (25 frames)\n",
      "\n",
      "Rep 16: Trigger at frame 52611\n",
      "  Window: [52571, 52691]\n",
      "  Detected: OL 55 vs DL 97\n",
      "  Rep frames: 52600 - 52652 (52 frames)\n",
      "\n",
      "Rep 17: Trigger at frame 52893\n",
      "  Window: [52853, 52973]\n",
      "  Detected: OL 55 vs DL 97\n",
      "  Rep frames: 52882 - 52924 (42 frames)\n",
      "\n",
      "Rep 18: Trigger at frame 53200\n",
      "  Window: [53160, 53280]\n",
      "  Detected: OL 75 vs DL 6\n",
      "  Rep frames: 53185 - 53234 (49 frames)\n",
      "\n",
      "Rep 19: Trigger at frame 53406\n",
      "  Window: [53366, 53486]\n",
      "  Detected: OL 55 vs DL 6\n",
      "  Rep frames: 53391 - 53426 (35 frames)\n",
      "\n",
      "Rep 20: Trigger at frame 53654\n",
      "  Window: [53614, 53734]\n",
      "  Detected: OL 75 vs DL 7\n",
      "  Rep frames: 53639 - 53675 (36 frames)\n",
      "\n",
      "Rep 21: Trigger at frame 53907\n",
      "  Window: [53867, 53987]\n",
      "  Detected: OL 75 vs DL 7\n",
      "  Rep frames: 53895 - 53929 (34 frames)\n",
      "\n",
      "Rep 22: Trigger at frame 54097\n",
      "  Window: [54057, 54177]\n",
      "  Detected: OL 70 vs DL 9\n",
      "  Rep frames: 54097 - 54141 (44 frames)\n",
      "\n",
      "Rep 23: Trigger at frame 54261\n",
      "  Window: [54221, 54341]\n",
      "  Detected: OL 70 vs DL 9\n",
      "  Rep frames: 54261 - 54295 (34 frames)\n",
      "\n",
      "Rep 24: Trigger at frame 54483\n",
      "  Window: [54443, 54563]\n",
      "  Detected: OL 73 vs DL 85\n",
      "  Rep frames: 54476 - 54502 (26 frames)\n",
      "\n",
      "Rep 25: Trigger at frame 54800\n",
      "  Window: [54760, 54880]\n",
      "  Detected: OL 73 vs DL 85\n",
      "  Rep frames: 54787 - 54853 (66 frames)\n",
      "\n",
      "Rep 26: Trigger at frame 55027\n",
      "  Window: [54987, 55107]\n",
      "  Detected: OL 69 vs DL 52\n",
      "  Rep frames: 55016 - 55061 (45 frames)\n",
      "\n",
      "Rep 27: Trigger at frame 55215\n",
      "  Window: [55175, 55295]\n",
      "  Detected: OL 69 vs DL 52\n",
      "  Rep frames: 55202 - 55244 (42 frames)\n",
      "\n",
      "Rep 28: Trigger at frame 55442\n",
      "  Window: [55402, 55522]\n",
      "  Detected: OL 55 vs DL 8\n",
      "  Rep frames: 55431 - 55479 (48 frames)\n",
      "\n",
      "Rep 29: Trigger at frame 55711\n",
      "  Window: [55671, 55791]\n",
      "  Detected: OL 55 vs DL 8\n",
      "  Rep frames: 55698 - 55740 (42 frames)\n",
      "\n",
      "Rep 30: Trigger at frame 55902\n",
      "  Window: [55862, 55982]\n",
      "  Detected: OL 78 vs DL 91\n",
      "  Rep frames: 55899 - 55930 (31 frames)\n",
      "\n",
      "Rep 31: Trigger at frame 56125\n",
      "  Window: [56085, 56205]\n",
      "  Detected: OL 78 vs DL 91\n",
      "  Rep frames: 56115 - 56147 (32 frames)\n",
      "\n",
      "Rep 32: Trigger at frame 56429\n",
      "  Window: [56389, 56509]\n",
      "  Detected: OL 77 vs DL 58\n",
      "  Rep frames: 56414 - 56448 (34 frames)\n",
      "\n",
      "Rep 33: Trigger at frame 56635\n",
      "  Window: [56595, 56715]\n",
      "  Detected: OL 77 vs DL 58\n",
      "  Rep frames: 56626 - 56654 (28 frames)\n",
      "No more triggers found after frame 56706\n",
      "\n",
      "======================================================================\n",
      "Supra-algorithm complete. Detected 33 reps.\n",
      "\n",
      "============================================================\n",
      "DETECTED 33 REPS\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (33, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>rep_number</th><th>rep_start_frame</th><th>rep_end_frame</th><th>ol_jersey</th><th>dl_jersey</th><th>ol_zebra_id</th><th>dl_zebra_id</th><th>start_ts</th><th>end_ts</th><th>duration_frames</th><th>duration_seconds</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>str</td><td>i64</td><td>f64</td></tr></thead><tbody><tr><td>1</td><td>49815</td><td>49842</td><td>&quot;71&quot;</td><td>&quot;91&quot;</td><td>&quot;1770000086&quot;</td><td>&quot;1770000135&quot;</td><td>&quot;2024-01-27T17:14:14.200&quot;</td><td>&quot;2024-01-27T17:14:16.900&quot;</td><td>28</td><td>2.8</td></tr><tr><td>2</td><td>50029</td><td>50073</td><td>&quot;71&quot;</td><td>&quot;91&quot;</td><td>&quot;1770000086&quot;</td><td>&quot;1770000135&quot;</td><td>&quot;2024-01-27T17:14:35.600&quot;</td><td>&quot;2024-01-27T17:14:40.000&quot;</td><td>45</td><td>4.5</td></tr><tr><td>3</td><td>50163</td><td>50205</td><td>&quot;69&quot;</td><td>&quot;8&quot;</td><td>&quot;1770000089&quot;</td><td>&quot;1770000099&quot;</td><td>&quot;2024-01-27T17:14:49.000&quot;</td><td>&quot;2024-01-27T17:14:53.200&quot;</td><td>43</td><td>4.3</td></tr><tr><td>4</td><td>50342</td><td>50375</td><td>&quot;69&quot;</td><td>&quot;8&quot;</td><td>&quot;1770000089&quot;</td><td>&quot;1770000099&quot;</td><td>&quot;2024-01-27T17:15:06.900&quot;</td><td>&quot;2024-01-27T17:15:10.200&quot;</td><td>34</td><td>3.4</td></tr><tr><td>5</td><td>50465</td><td>50502</td><td>&quot;54&quot;</td><td>&quot;52&quot;</td><td>&quot;1770000095&quot;</td><td>&quot;1770000101&quot;</td><td>&quot;2024-01-27T17:15:19.200&quot;</td><td>&quot;2024-01-27T17:15:22.900&quot;</td><td>38</td><td>3.8</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>29</td><td>55698</td><td>55740</td><td>&quot;55&quot;</td><td>&quot;8&quot;</td><td>&quot;1770000094&quot;</td><td>&quot;1770000099&quot;</td><td>&quot;2024-01-27T17:24:02.500&quot;</td><td>&quot;2024-01-27T17:24:06.700&quot;</td><td>43</td><td>4.3</td></tr><tr><td>30</td><td>55899</td><td>55930</td><td>&quot;78&quot;</td><td>&quot;91&quot;</td><td>&quot;1770000092&quot;</td><td>&quot;1770000135&quot;</td><td>&quot;2024-01-27T17:24:22.600&quot;</td><td>&quot;2024-01-27T17:24:25.700&quot;</td><td>32</td><td>3.2</td></tr><tr><td>31</td><td>56115</td><td>56147</td><td>&quot;78&quot;</td><td>&quot;91&quot;</td><td>&quot;1770000092&quot;</td><td>&quot;1770000135&quot;</td><td>&quot;2024-01-27T17:24:44.200&quot;</td><td>&quot;2024-01-27T17:24:47.400&quot;</td><td>33</td><td>3.3</td></tr><tr><td>32</td><td>56414</td><td>56448</td><td>&quot;77&quot;</td><td>&quot;58&quot;</td><td>&quot;1770000084&quot;</td><td>&quot;1770000103&quot;</td><td>&quot;2024-01-27T17:25:14.100&quot;</td><td>&quot;2024-01-27T17:25:17.500&quot;</td><td>35</td><td>3.5</td></tr><tr><td>33</td><td>56626</td><td>56654</td><td>&quot;77&quot;</td><td>&quot;58&quot;</td><td>&quot;1770000084&quot;</td><td>&quot;1770000103&quot;</td><td>&quot;2024-01-27T17:25:35.300&quot;</td><td>&quot;2024-01-27T17:25:38.100&quot;</td><td>29</td><td>2.9</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (33, 11)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ rep_numbe ┆ rep_start ┆ rep_end_f ┆ ol_jersey ┆ … ┆ start_ts  ┆ end_ts    ┆ duration_ ┆ duration │\n",
       "│ r         ┆ _frame    ┆ rame      ┆ ---       ┆   ┆ ---       ┆ ---       ┆ frames    ┆ _seconds │\n",
       "│ ---       ┆ ---       ┆ ---       ┆ str       ┆   ┆ str       ┆ str       ┆ ---       ┆ ---      │\n",
       "│ i64       ┆ i64       ┆ i64       ┆           ┆   ┆           ┆           ┆ i64       ┆ f64      │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 1         ┆ 49815     ┆ 49842     ┆ 71        ┆ … ┆ 2024-01-2 ┆ 2024-01-2 ┆ 28        ┆ 2.8      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 7T17:14:1 ┆ 7T17:14:1 ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 4.200     ┆ 6.900     ┆           ┆          │\n",
       "│ 2         ┆ 50029     ┆ 50073     ┆ 71        ┆ … ┆ 2024-01-2 ┆ 2024-01-2 ┆ 45        ┆ 4.5      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 7T17:14:3 ┆ 7T17:14:4 ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 5.600     ┆ 0.000     ┆           ┆          │\n",
       "│ 3         ┆ 50163     ┆ 50205     ┆ 69        ┆ … ┆ 2024-01-2 ┆ 2024-01-2 ┆ 43        ┆ 4.3      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 7T17:14:4 ┆ 7T17:14:5 ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 9.000     ┆ 3.200     ┆           ┆          │\n",
       "│ 4         ┆ 50342     ┆ 50375     ┆ 69        ┆ … ┆ 2024-01-2 ┆ 2024-01-2 ┆ 34        ┆ 3.4      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 7T17:15:0 ┆ 7T17:15:1 ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 6.900     ┆ 0.200     ┆           ┆          │\n",
       "│ 5         ┆ 50465     ┆ 50502     ┆ 54        ┆ … ┆ 2024-01-2 ┆ 2024-01-2 ┆ 38        ┆ 3.8      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 7T17:15:1 ┆ 7T17:15:2 ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 9.200     ┆ 2.900     ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ 29        ┆ 55698     ┆ 55740     ┆ 55        ┆ … ┆ 2024-01-2 ┆ 2024-01-2 ┆ 43        ┆ 4.3      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 7T17:24:0 ┆ 7T17:24:0 ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 2.500     ┆ 6.700     ┆           ┆          │\n",
       "│ 30        ┆ 55899     ┆ 55930     ┆ 78        ┆ … ┆ 2024-01-2 ┆ 2024-01-2 ┆ 32        ┆ 3.2      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 7T17:24:2 ┆ 7T17:24:2 ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 2.600     ┆ 5.700     ┆           ┆          │\n",
       "│ 31        ┆ 56115     ┆ 56147     ┆ 78        ┆ … ┆ 2024-01-2 ┆ 2024-01-2 ┆ 33        ┆ 3.3      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 7T17:24:4 ┆ 7T17:24:4 ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 4.200     ┆ 7.400     ┆           ┆          │\n",
       "│ 32        ┆ 56414     ┆ 56448     ┆ 77        ┆ … ┆ 2024-01-2 ┆ 2024-01-2 ┆ 35        ┆ 3.5      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 7T17:25:1 ┆ 7T17:25:1 ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 4.100     ┆ 7.500     ┆           ┆          │\n",
       "│ 33        ┆ 56626     ┆ 56654     ┆ 77        ┆ … ┆ 2024-01-2 ┆ 2024-01-2 ┆ 29        ┆ 2.9      │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 7T17:25:3 ┆ 7T17:25:3 ┆           ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆ 5.300     ┆ 8.100     ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build jersey -> zebra_id lookup\n",
    "jersey_to_zebra = dict(\n",
    "    df_reps.select([\"jersey_number\", \"id\"]).unique().iter_rows()\n",
    ")\n",
    "\n",
    "# Get frame range\n",
    "start_frame = int(df_reps[\"frame_id\"].min())\n",
    "end_frame = int(df_reps[\"frame_id\"].max())\n",
    "\n",
    "# Run the algorithm\n",
    "results = run_supra_algorithm(df_reps, start_frame, end_frame, verbose=True)\n",
    "\n",
    "# Build output DataFrame\n",
    "output_df = build_output_dataframe(results, jersey_to_zebra)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"DETECTED {len(results)} REPS\")\n",
    "print(\"=\"*60)\n",
    "display(output_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CELL 9: VISUALIZE DETECTED REPS\n",
    "Use the dropdown to select a rep and view the frame-by-frame tracking data. This is helpful for validation and identifying false positives.\n",
    "\n",
    "- **Blue dots**: Offensive linemen\n",
    "- **Red dots**: Defensive linemen\n",
    "- **Highlighted**: The identified OL-DL pair for this rep\n",
    "- **Yellow dashed line**: LOS at x=0 (normalized coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-caching rep frames...\n",
      "Loaded 33 reps\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "425733c2e59e4a52b3f9d531ca8cdec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Rep', options=(('2024_West_Practice_1.snappy | rep 1 | OL 71 vs DL 91', (…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Viz (play-only, Plotly)\n",
    "if output_df.height == 0:\n",
    "    print(\"No reps detected. Check your configuration and try again.\")\n",
    "else:\n",
    "    if \"session_name\" in globals():\n",
    "        session_name_local = session_name\n",
    "    else:\n",
    "        session_name_local = PRACTICE_FILE.stem if \"PRACTICE_FILE\" in globals() else \"Session\"\n",
    "\n",
    "    frame_col = \"frame_id\"\n",
    "\n",
    "    rep_options = []\n",
    "    rep_meta = {}\n",
    "    for result in results:\n",
    "        rep_number = int(result.get(\"rep_number\"))\n",
    "        ol_jersey = result.get(\"ol_jersey\")\n",
    "        dl_jersey = result.get(\"dl_jersey\")\n",
    "        rep_key = (session_name_local, rep_number)\n",
    "        rep_meta[rep_key] = result\n",
    "        label = f\"{session_name_local} | rep {rep_number} | OL {ol_jersey} vs DL {dl_jersey}\"\n",
    "        rep_options.append((label, rep_key))\n",
    "\n",
    "    rep_options = sorted(rep_options, key=lambda x: x[1][1])\n",
    "\n",
    "    if not rep_options:\n",
    "        print(\"No reps available for visualization.\")\n",
    "    else:\n",
    "        # Visualization constants (normalized coords)\n",
    "        X_MIN = -15.0\n",
    "        X_MAX = 15.0\n",
    "        Y_MIN = 10.0\n",
    "        Y_MAX = 40.0\n",
    "\n",
    "        print(\"Pre-caching rep frames...\")\n",
    "        rep_cache = {}\n",
    "        for _, rep_key in rep_options:\n",
    "            meta = rep_meta.get(rep_key)\n",
    "            if meta is None:\n",
    "                continue\n",
    "\n",
    "            rep_start = meta.get(\"rep_start_frame\")\n",
    "            rep_end = meta.get(\"rep_end_frame\")\n",
    "            ol_jersey = str(meta.get(\"ol_jersey\"))\n",
    "            dl_jersey = str(meta.get(\"dl_jersey\"))\n",
    "\n",
    "            rep_df = (\n",
    "                df_reps\n",
    "                .filter((pl.col(\"frame_id\") >= rep_start) & (pl.col(\"frame_id\") <= rep_end))\n",
    "                .with_columns(pl.col(\"jersey_number\").cast(pl.Utf8))\n",
    "            )\n",
    "\n",
    "            if rep_df.height == 0:\n",
    "                continue\n",
    "\n",
    "            ol_df = (\n",
    "                rep_df\n",
    "                .filter(pl.col(\"jersey_number\") == ol_jersey)\n",
    "                .select([\"frame_id\", \"x\", \"y\"])\n",
    "                .unique(subset=[\"frame_id\"])\n",
    "                .sort(\"frame_id\")\n",
    "            )\n",
    "\n",
    "            dl_df = (\n",
    "                rep_df\n",
    "                .filter(pl.col(\"jersey_number\") == dl_jersey)\n",
    "                .select([\"frame_id\", \"x\", \"y\"])\n",
    "                .unique(subset=[\"frame_id\"])\n",
    "                .sort(\"frame_id\")\n",
    "            )\n",
    "\n",
    "            wide_df = ol_df.join(dl_df, on=\"frame_id\", how=\"inner\", suffix=\"_dl\").sort(\"frame_id\")\n",
    "            if wide_df.height == 0:\n",
    "                continue\n",
    "\n",
    "            frame_ids = wide_df[\"frame_id\"].to_list()\n",
    "\n",
    "            others_df = rep_df.filter(\n",
    "                (pl.col(\"frame_id\").is_in(frame_ids)) &\n",
    "                (~pl.col(\"jersey_number\").is_in([ol_jersey, dl_jersey]))\n",
    "            )\n",
    "\n",
    "            frame_groups = (\n",
    "                others_df\n",
    "                .group_by(\"frame_id\")\n",
    "                .agg(\n",
    "                    pl.col(\"x\").implode().alias(\"x\"),\n",
    "                    pl.col(\"y\").implode().alias(\"y\"),\n",
    "                    pl.col(\"jersey_number\").implode().alias(\"jersey\"),\n",
    "                )\n",
    "                .sort(\"frame_id\")\n",
    "            )\n",
    "\n",
    "            others_by_frame = {\n",
    "                row[\"frame_id\"]: (row[\"x\"], row[\"y\"], row[\"jersey\"])\n",
    "                for row in frame_groups.iter_rows(named=True)\n",
    "            }\n",
    "\n",
    "            ts_by_frame = {\n",
    "                row[\"frame_id\"]: row[\"ts\"]\n",
    "                for row in rep_df.select([\"frame_id\", \"ts\"]).unique().iter_rows(named=True)\n",
    "            }\n",
    "\n",
    "            rep_cache[rep_key] = {\n",
    "                \"session\": rep_key[0],\n",
    "                \"rep_number\": rep_key[1],\n",
    "                \"frame_ids\": frame_ids,\n",
    "                \"ol_x\": wide_df[\"x\"].to_list(),\n",
    "                \"ol_y\": wide_df[\"y\"].to_list(),\n",
    "                \"dl_x\": wide_df[\"x_dl\"].to_list(),\n",
    "                \"dl_y\": wide_df[\"y_dl\"].to_list(),\n",
    "                \"ol_jersey\": ol_jersey,\n",
    "                \"dl_jersey\": dl_jersey,\n",
    "                \"others_by_frame\": others_by_frame,\n",
    "                \"ts_by_frame\": ts_by_frame,\n",
    "            }\n",
    "\n",
    "        print(f\"Loaded {len(rep_cache)} reps\")\n",
    "\n",
    "        # ====== Figure ======\n",
    "        import plotly.graph_objects as go\n",
    "\n",
    "        fig = go.FigureWidget()\n",
    "\n",
    "        # Yard lines\n",
    "        for x_val in range(int(X_MIN), int(X_MAX) + 1, 5):\n",
    "            color = \"yellow\" if x_val == 0 else \"rgba(255,255,255,0.5)\"\n",
    "            width = 2 if x_val == 0 else 1\n",
    "            fig.add_shape(\n",
    "                type=\"line\",\n",
    "                x0=x_val, x1=x_val,\n",
    "                y0=Y_MIN, y1=Y_MAX,\n",
    "                line=dict(color=color, width=width),\n",
    "                layer=\"below\",\n",
    "            )\n",
    "\n",
    "        # Other players (faded)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[], y=[], mode=\"markers\", name=\"Other Players\",\n",
    "            marker=dict(size=8, color=\"rgba(220,220,220,0.5)\", line=dict(color=\"rgba(255,255,255,0.4)\", width=1)),\n",
    "            showlegend=True,\n",
    "        ))\n",
    "\n",
    "        # OL highlight\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[], y=[], mode=\"markers+text\", name=\"OL\",\n",
    "            marker=dict(size=18, color=\"dodgerblue\", line=dict(color=\"white\", width=2)),\n",
    "            text=[], textposition=\"middle center\",\n",
    "            textfont=dict(color=\"white\", size=10),\n",
    "            showlegend=True,\n",
    "        ))\n",
    "\n",
    "        # DL highlight\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[], y=[], mode=\"markers+text\", name=\"DL\",\n",
    "            marker=dict(size=18, color=\"red\", line=dict(color=\"white\", width=2)),\n",
    "            text=[], textposition=\"middle center\",\n",
    "            textfont=dict(color=\"white\", size=10),\n",
    "            showlegend=True,\n",
    "        ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            width=900, height=500,\n",
    "            title=\"\",\n",
    "            showlegend=True,\n",
    "            legend=dict(x=0.02, y=0.98),\n",
    "            plot_bgcolor=\"#2e7d32\",\n",
    "            paper_bgcolor=\"white\",\n",
    "        )\n",
    "\n",
    "        fig.update_xaxes(range=[X_MIN, X_MAX], title=\"X (yards)\", showgrid=False, zeroline=False)\n",
    "        fig.update_yaxes(range=[Y_MIN, Y_MAX], title=\"Y (yards)\", showgrid=False, zeroline=False, scaleanchor=\"x\", scaleratio=1)\n",
    "\n",
    "        # ====== Widgets ======\n",
    "        rep_dropdown = Dropdown(options=rep_options, description=\"Rep\")\n",
    "        play = Play(interval=200, min=0, max=1, step=1, value=0)\n",
    "        frame_slider = IntSlider(min=0, max=1, step=1, value=0, description=\"Frame\")\n",
    "        back_button = Button(description=\"<\")\n",
    "        forward_button = Button(description=\">\")\n",
    "\n",
    "        current_data = {\"ref\": None}\n",
    "\n",
    "        def update_plot(frame_idx):\n",
    "            data = current_data[\"ref\"]\n",
    "            if data is None:\n",
    "                return\n",
    "            idx = max(0, min(frame_idx, len(data[\"frame_ids\"]) - 1))\n",
    "            frame_id = data[\"frame_ids\"][idx]\n",
    "            other_xy = data[\"others_by_frame\"].get(frame_id, ([], [], []))\n",
    "            ts = data[\"ts_by_frame\"].get(frame_id, \"\")\n",
    "\n",
    "            with fig.batch_update():\n",
    "                # Other players\n",
    "                fig.data[0].x = other_xy[0]\n",
    "                fig.data[0].y = other_xy[1]\n",
    "\n",
    "                # OL/DL\n",
    "                fig.data[1].x = [data[\"ol_x\"][idx]]\n",
    "                fig.data[1].y = [data[\"ol_y\"][idx]]\n",
    "                fig.data[1].text = [data[\"ol_jersey\"]]\n",
    "                fig.data[2].x = [data[\"dl_x\"][idx]]\n",
    "                fig.data[2].y = [data[\"dl_y\"][idx]]\n",
    "                fig.data[2].text = [data[\"dl_jersey\"]]\n",
    "\n",
    "                fig.layout.title = (\n",
    "                    f\"{data['session']} | rep {data['rep_number']} | {frame_col} {frame_id} | {ts}\"\n",
    "                )\n",
    "\n",
    "        def load_rep(rep_key):\n",
    "            if rep_key not in rep_cache:\n",
    "                return\n",
    "            current_data[\"ref\"] = rep_cache[rep_key]\n",
    "            data = current_data[\"ref\"]\n",
    "            max_idx = len(data[\"frame_ids\"]) - 1\n",
    "\n",
    "            frame_slider.max = max_idx\n",
    "            play.max = max_idx\n",
    "            frame_slider.value = 0\n",
    "            update_plot(0)\n",
    "\n",
    "        def on_rep_change(change):\n",
    "            if change[\"name\"] == \"value\":\n",
    "                load_rep(change[\"new\"])\n",
    "\n",
    "        def on_frame_change(change):\n",
    "            if change[\"name\"] == \"value\":\n",
    "                update_plot(change[\"new\"])\n",
    "\n",
    "        jslink((play, \"value\"), (frame_slider, \"value\"))\n",
    "        rep_dropdown.observe(on_rep_change, names=\"value\")\n",
    "        frame_slider.observe(on_frame_change, names=\"value\")\n",
    "        back_button.on_click(lambda _: setattr(frame_slider, \"value\", max(0, frame_slider.value - 1)))\n",
    "        forward_button.on_click(lambda _: setattr(frame_slider, \"value\", min(frame_slider.max, frame_slider.value + 1)))\n",
    "\n",
    "        controls = HBox([play, back_button, forward_button, frame_slider])\n",
    "        ui = VBox([rep_dropdown, controls, fig])\n",
    "        display(ui)\n",
    "\n",
    "        load_rep(rep_dropdown.value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CELL 11: WRITE THE DF TO A CSV\n",
    "Save the df to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample (first 5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 29)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>session_name</th><th>rep_number</th><th>frame_id</th><th>ts</th><th>ol_a</th><th>ol_dir</th><th>ol_dis</th><th>ol_gsis_id</th><th>ol_id</th><th>ol_jersey_number</th><th>ol_s</th><th>ol_sa</th><th>ol_x</th><th>ol_y</th><th>ol_z</th><th>dl_a</th><th>dl_dir</th><th>dl_dis</th><th>dl_gsis_id</th><th>dl_id</th><th>dl_jersey_number</th><th>dl_s</th><th>dl_sa</th><th>dl_x</th><th>dl_y</th><th>dl_z</th><th>pairwise_distance</th><th>distance_change</th><th>frame_delta</th></tr><tr><td>str</td><td>i32</td><td>u32</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>u32</td></tr></thead><tbody><tr><td>&quot;2024WestPractice1&quot;</td><td>1</td><td>49815</td><td>&quot;2024-01-27T17:14:14.200&quot;</td><td>0.715876</td><td>114.639725</td><td>0.0005</td><td>&quot;327296&quot;</td><td>&quot;1770000086&quot;</td><td>&quot;71&quot;</td><td>0.311376</td><td>0.593745</td><td>0.440745</td><td>23.378616</td><td>2.0</td><td>1.076955</td><td>75.683302</td><td>0.001114</td><td>&quot;325899&quot;</td><td>&quot;1770000135&quot;</td><td>&quot;91&quot;</td><td>0.477003</td><td>1.076862</td><td>-0.514781</td><td>21.168608</td><td>2.0</td><td>2.40773</td><td>null</td><td>null</td></tr><tr><td>&quot;2024WestPractice1&quot;</td><td>1</td><td>49816</td><td>&quot;2024-01-27T17:14:14.300&quot;</td><td>0.819911</td><td>110.90028</td><td>0.000721</td><td>&quot;327296&quot;</td><td>&quot;1770000086&quot;</td><td>&quot;71&quot;</td><td>0.393735</td><td>0.774361</td><td>0.46759</td><td>23.373589</td><td>2.0</td><td>1.417541</td><td>75.781828</td><td>0.001547</td><td>&quot;325899&quot;</td><td>&quot;1770000135&quot;</td><td>&quot;91&quot;</td><td>0.631631</td><td>1.417333</td><td>-0.475474</td><td>21.177973</td><td>2.0</td><td>2.389581</td><td>-0.018149</td><td>1</td></tr><tr><td>&quot;2024WestPractice1&quot;</td><td>1</td><td>49817</td><td>&quot;2024-01-27T17:14:14.400&quot;</td><td>1.235503</td><td>114.96914</td><td>0.000745</td><td>&quot;327296&quot;</td><td>&quot;1770000086&quot;</td><td>&quot;71&quot;</td><td>0.55266</td><td>1.234527</td><td>0.49471</td><td>23.384496</td><td>2.0</td><td>1.637186</td><td>75.301393</td><td>0.003361</td><td>&quot;325899&quot;</td><td>&quot;1770000135&quot;</td><td>&quot;91&quot;</td><td>0.817225</td><td>1.636394</td><td>-0.417531</td><td>21.190806</td><td>2.0</td><td>2.375807</td><td>-0.013773</td><td>1</td></tr><tr><td>&quot;2024WestPractice1&quot;</td><td>1</td><td>49818</td><td>&quot;2024-01-27T17:14:14.500&quot;</td><td>1.487852</td><td>116.732955</td><td>0.002573</td><td>&quot;327296&quot;</td><td>&quot;1770000086&quot;</td><td>&quot;71&quot;</td><td>0.716564</td><td>1.479584</td><td>0.544983</td><td>23.362483</td><td>2.0</td><td>1.663369</td><td>74.854191</td><td>0.007851</td><td>&quot;325899&quot;</td><td>&quot;1770000135&quot;</td><td>&quot;91&quot;</td><td>0.998911</td><td>1.662188</td><td>-0.329041</td><td>21.214494</td><td>2.0</td><td>2.319002</td><td>-0.056805</td><td>1</td></tr><tr><td>&quot;2024WestPractice1&quot;</td><td>1</td><td>49819</td><td>&quot;2024-01-27T17:14:14.600&quot;</td><td>1.851712</td><td>118.53101</td><td>0.003872</td><td>&quot;327296&quot;</td><td>&quot;1770000086&quot;</td><td>&quot;71&quot;</td><td>0.926649</td><td>1.831969</td><td>0.606354</td><td>23.332492</td><td>2.0</td><td>2.043224</td><td>74.733885</td><td>0.010068</td><td>&quot;325899&quot;</td><td>&quot;1770000135&quot;</td><td>&quot;91&quot;</td><td>1.213979</td><td>2.041493</td><td>-0.228841</td><td>21.241914</td><td>2.0</td><td>2.251236</td><td>-0.067766</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 29)\n",
       "┌────────────┬────────────┬──────────┬────────────┬───┬──────┬────────────┬────────────┬───────────┐\n",
       "│ session_na ┆ rep_number ┆ frame_id ┆ ts         ┆ … ┆ dl_z ┆ pairwise_d ┆ distance_c ┆ frame_del │\n",
       "│ me         ┆ ---        ┆ ---      ┆ ---        ┆   ┆ ---  ┆ istance    ┆ hange      ┆ ta        │\n",
       "│ ---        ┆ i32        ┆ u32      ┆ str        ┆   ┆ f64  ┆ ---        ┆ ---        ┆ ---       │\n",
       "│ str        ┆            ┆          ┆            ┆   ┆      ┆ f64        ┆ f64        ┆ u32       │\n",
       "╞════════════╪════════════╪══════════╪════════════╪═══╪══════╪════════════╪════════════╪═══════════╡\n",
       "│ 2024WestPr ┆ 1          ┆ 49815    ┆ 2024-01-27 ┆ … ┆ 2.0  ┆ 2.40773    ┆ null       ┆ null      │\n",
       "│ actice1    ┆            ┆          ┆ T17:14:14. ┆   ┆      ┆            ┆            ┆           │\n",
       "│            ┆            ┆          ┆ 200        ┆   ┆      ┆            ┆            ┆           │\n",
       "│ 2024WestPr ┆ 1          ┆ 49816    ┆ 2024-01-27 ┆ … ┆ 2.0  ┆ 2.389581   ┆ -0.018149  ┆ 1         │\n",
       "│ actice1    ┆            ┆          ┆ T17:14:14. ┆   ┆      ┆            ┆            ┆           │\n",
       "│            ┆            ┆          ┆ 300        ┆   ┆      ┆            ┆            ┆           │\n",
       "│ 2024WestPr ┆ 1          ┆ 49817    ┆ 2024-01-27 ┆ … ┆ 2.0  ┆ 2.375807   ┆ -0.013773  ┆ 1         │\n",
       "│ actice1    ┆            ┆          ┆ T17:14:14. ┆   ┆      ┆            ┆            ┆           │\n",
       "│            ┆            ┆          ┆ 400        ┆   ┆      ┆            ┆            ┆           │\n",
       "│ 2024WestPr ┆ 1          ┆ 49818    ┆ 2024-01-27 ┆ … ┆ 2.0  ┆ 2.319002   ┆ -0.056805  ┆ 1         │\n",
       "│ actice1    ┆            ┆          ┆ T17:14:14. ┆   ┆      ┆            ┆            ┆           │\n",
       "│            ┆            ┆          ┆ 500        ┆   ┆      ┆            ┆            ┆           │\n",
       "│ 2024WestPr ┆ 1          ┆ 49819    ┆ 2024-01-27 ┆ … ┆ 2.0  ┆ 2.251236   ┆ -0.067766  ┆ 1         │\n",
       "│ actice1    ┆            ┆          ┆ T17:14:14. ┆   ┆      ┆            ┆            ┆           │\n",
       "│            ┆            ┆          ┆ 600        ┆   ┆      ┆            ┆            ┆           │\n",
       "└────────────┴────────────┴──────────┴────────────┴───┴──────┴────────────┴────────────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save Summary and Wide Format\n",
    "session_name = \"2024WestPractice1\"\n",
    "output_dir = Path(\"~/Desktop/\").expanduser() # Or change to your desired output directory\n",
    "summary_filepath = output_dir / f\"{session_name}_summary.csv\"\n",
    "\n",
    "# Save summary DataFrame \n",
    "# output_df.with_columns(pl.lit(session_name).alias(\"session_name\")).write_csv(summary_filepath)\n",
    "\n",
    "# Build and save wide-format rep timeseries\n",
    "def build_wide_rep_data(df_reps: pl.DataFrame, result: dict) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Build wide-format DataFrame for a single rep's OL-DL pair.\n",
    "    Includes all frames from rep_start to rep_end with metrics for both players.\n",
    "    \"\"\"\n",
    "    rep_start = result['rep_start_frame']\n",
    "    rep_end = result['rep_end_frame']\n",
    "    ol_jersey = result['ol_jersey']\n",
    "    dl_jersey = result['dl_jersey']\n",
    "    rep_number = result['rep_number']\n",
    "    \n",
    "    # Filter to rep frames\n",
    "    rep_df = df_reps.filter(\n",
    "        (pl.col(\"frame_id\") >= rep_start) &\n",
    "        (pl.col(\"frame_id\") <= rep_end)\n",
    "    )\n",
    "    \n",
    "    # Columns to include for each player\n",
    "    base_cols = [\"frame_id\", \"ts\"]\n",
    "    metric_cols = [\"x\", \"y\", \"s\", \"a\", \"dir\", \"z\", \"sa\", \"dis\"]\n",
    "    id_cols = [\"jersey_number\", \"gsis_id\", \"id\"]  # id is zebra_id\n",
    "    \n",
    "    # Filter to available columns\n",
    "    all_player_cols = metric_cols + id_cols\n",
    "    available_cols = [c for c in all_player_cols if c in rep_df.columns]\n",
    "    select_cols = base_cols + available_cols\n",
    "    \n",
    "    # Get OL data - deduplicate by frame_id to handle any duplicate rows\n",
    "    ol_data = (\n",
    "        rep_df\n",
    "        .filter(pl.col(\"jersey_number\") == ol_jersey)\n",
    "        .select([c for c in select_cols if c in rep_df.columns])\n",
    "        .unique(subset=[\"frame_id\"])  # Deduplicate by frame_id\n",
    "        .sort(\"frame_id\")\n",
    "    )\n",
    "    \n",
    "    # Rename OL columns (except frame_id, ts)\n",
    "    ol_rename = {c: f\"ol_{c}\" for c in available_cols}\n",
    "    ol_data = ol_data.rename(ol_rename)\n",
    "    \n",
    "    # Get DL data - deduplicate by frame_id to handle any duplicate rows\n",
    "    dl_data = (\n",
    "        rep_df\n",
    "        .filter(pl.col(\"jersey_number\") == dl_jersey)\n",
    "        .select([c for c in select_cols if c in rep_df.columns])\n",
    "        .unique(subset=[\"frame_id\"])  # Deduplicate by frame_id\n",
    "        .sort(\"frame_id\")\n",
    "    )\n",
    "    \n",
    "    # Rename DL columns (except frame_id, ts)\n",
    "    dl_rename = {c: f\"dl_{c}\" for c in available_cols}\n",
    "    dl_data = dl_data.rename(dl_rename)\n",
    "    \n",
    "    # Join on frame_id (inner join - only frames where both players have data)\n",
    "    wide_df = ol_data.join(dl_data.drop(\"ts\"), on=\"frame_id\", how=\"inner\")\n",
    "    \n",
    "    if wide_df.height == 0:\n",
    "        return None\n",
    "    \n",
    "    # Add rep_number and session_name\n",
    "    wide_df = wide_df.with_columns([\n",
    "        pl.lit(rep_number).alias(\"rep_number\"),\n",
    "        pl.lit(session_name).alias(\"session_name\"),\n",
    "    ])\n",
    "    \n",
    "    # Add pairwise distance\n",
    "    wide_df = wide_df.with_columns(\n",
    "        (((pl.col(\"ol_x\") - pl.col(\"dl_x\"))**2 + (pl.col(\"ol_y\") - pl.col(\"dl_y\"))**2).sqrt())\n",
    "        .alias(\"pairwise_distance\")\n",
    "    )\n",
    "    \n",
    "    # Add distance change\n",
    "    wide_df = wide_df.with_columns(\n",
    "        (pl.col(\"pairwise_distance\") - pl.col(\"pairwise_distance\").shift(1))\n",
    "        .alias(\"distance_change\")\n",
    "    )\n",
    "    \n",
    "    # Add frame delta\n",
    "    wide_df = wide_df.with_columns(\n",
    "        (pl.col(\"frame_id\") - pl.col(\"frame_id\").shift(1))\n",
    "        .alias(\"frame_delta\")\n",
    "    )\n",
    "    \n",
    "    return wide_df\n",
    "\n",
    "# Build combined wide rep data\n",
    "all_wide_reps = []\n",
    "for result in results:\n",
    "    wide_rep = build_wide_rep_data(df_reps, result)\n",
    "    if wide_rep is not None:\n",
    "        all_wide_reps.append(wide_rep)\n",
    "\n",
    "if all_wide_reps:\n",
    "    combined_wide_df = pl.concat(all_wide_reps, how=\"vertical\")\n",
    "    \n",
    "    # Reorder columns: identifiers first, then OL metrics, then DL metrics, then derived\n",
    "    id_cols_order = [\"session_name\", \"rep_number\", \"frame_id\", \"ts\"]\n",
    "    ol_cols = [c for c in combined_wide_df.columns if c.startswith(\"ol_\")]\n",
    "    dl_cols = [c for c in combined_wide_df.columns if c.startswith(\"dl_\")]\n",
    "    derived_cols = [\"pairwise_distance\", \"distance_change\", \"frame_delta\"]\n",
    "    \n",
    "    # Build final column order\n",
    "    final_cols = id_cols_order + sorted(ol_cols) + sorted(dl_cols) + derived_cols\n",
    "    final_cols = [c for c in final_cols if c in combined_wide_df.columns]\n",
    "    combined_wide_df = combined_wide_df.select(final_cols)\n",
    "    \n",
    "    # Save wide rep data\n",
    "    wide_filepath = output_dir / f\"{session_name}_wide_reps.csv\"\n",
    "    # combined_wide_df.write_csv(wide_filepath)\n",
    "    \n",
    "    # Show sample\n",
    "    print(f\"\\nSample (first 5 rows):\")\n",
    "    display(combined_wide_df.head(5))\n",
    "else:\n",
    "    print(\"No rep data to save.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADDENDUM: FILTERING OUT FALSE POSITIVES\n",
    "The algorithm will detect a small amount of false positives. Those can be filtered out by manual inspection. For reference, and will be filtered out in the automated pipeline in data_pipeline_automated.ipynb."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS_ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
